# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## ğŸ§  Project Overview

Brain-Go-Brr v2: First Bi-Mamba-2 + U-Net + ResCNN for clinical EEG seizure detection â€” O(N) sequence modeling with bidirectional SSM.

Why this is different:
- Transformers struggle on long EEG (O(NÂ²) cost)
- Pure CNNs miss global temporal context
- Bidirectional Mamba-2 brings O(N) global context efficiently

## âš¡ Essential Commands

| Command | Purpose |
|---------|---------|
| `make q` | Quality check (lint+format+mypy) â€” RUN AFTER EVERY CHANGE âœ… |
| `make t` | Fast tests (no coverage) |
| `make test` | Full tests with coverage |
| `make test-gpu` | GPU-specific tests |
| `make setup` | Initial setup (uv, hooks) |
| `make train-local` | Smoke test config (1 epoch, small batch) |
| `uv sync -E gpu` | GPU extra (Mamba-SSM) |
| `uv sync -E post,eval` | Extras: post-proc + eval |
| `python -m src train configs/smoke_test.yaml` | Direct training command |

## ğŸ—ï¸ Architecture

| Component | Specification | Location |
|-----------|--------------|----------|
| Input | 19-channel EEG @ 256 Hz | - |
| U-Net Encoder | [64, 128, 256, 512] channels, Ã—16 downsample | `src/brain_brr/models/unet.py` |
| ResCNN | 3 blocks, kernels [3, 5, 7] | `src/brain_brr/models/rescnn.py` |
| Bi-Mamba-2 | 6 layers, d_model=512, d_state=16 | `src/brain_brr/models/mamba.py` |
| Hysteresis | tau_on=0.86, tau_off=0.78 | `src/brain_brr/post/postprocess.py` |
| Output | Per-timestep probabilities | - |

Full architecture specification: `CANONICAL_ARCHITECTURE_SPEC.md`

## ğŸ“ Project Structure

```
src/brain_brr/      # Core modules (refactored from /experiments/)
â”œâ”€â”€ models/         # Neural network components
â”‚   â”œâ”€â”€ detector.py # Main SeizureDetector class
â”‚   â”œâ”€â”€ unet.py    # U-Net encoder/decoder
â”‚   â”œâ”€â”€ rescnn.py  # Residual CNN blocks
â”‚   â””â”€â”€ mamba.py   # Bidirectional Mamba-2
â”œâ”€â”€ data/          # EEG preprocessing
â”‚   â”œâ”€â”€ loader.py  # EDF handling with MNE
â”‚   â””â”€â”€ dataset.py # PyTorch Dataset
â”œâ”€â”€ train/         # Training pipeline
â”œâ”€â”€ post/          # Post-processing
â”œâ”€â”€ eval/          # Evaluation (TAES)
â”œâ”€â”€ events/        # Event generation
â””â”€â”€ config/        # Pydantic schemas

configs/           # YAML experiments
tests/             # Pytest suite
data/              # Datasets (git-ignored)
results/           # Outputs (git-ignored)
```

## Critical Implementation Details

### Channel Ordering
MUST maintain canonical 10-20 montage order (defined in `src/brain_brr/constants.py`):
```python
["Fp1", "F3", "C3", "P3", "F7", "T3", "T5", "O1",
 "Fz", "Cz", "Pz",
 "Fp2", "F4", "C4", "P4", "F8", "T4", "T6", "O2"]
```

### Mamba CUDA Dispatch
- Configured d_conv=5, but CUDA kernels only support {2,3,4}
- Internally coerces to 4 for CUDA path
- Set `SEIZURE_MAMBA_FORCE_FALLBACK=1` to force Conv1d fallback

### Post-Processing Pipeline
Hysteresis thresholds (tau_on=0.86, tau_off=0.78) â†’ morphology â†’ duration filtering â†’ event generation

## ğŸ¯ Clinical Targets (TAES)

- 10 FA/24h: >95% sensitivity (current SOTA: ~90%)
- 5 FA/24h: >90% sensitivity (current SOTA: ~85%)
- 1 FA/24h: >75% sensitivity (current SOTA: ~70%)

## ğŸ”§ Development Rules

1. Quality first: run `make q` after EVERY change ğŸ§¹
2. Type everything: full type hints required
3. Tests required for new functions (unit/integration markers)
4. No comments unless explicitly requested
5. Follow neighboring file patterns; preserve `src/brain_brr/` APIs

Code style:
- Python 3.11+, 4-space indent, Ruff line length 100
- Imports: stdlib â†’ third-party â†’ first-party (sorted)

## ğŸ“Š Data Pipeline

1. Read EDF via MNE; 10-20 montage
2. Bandpass 0.5â€“120 Hz; 60 Hz notch
3. Resample to 256 Hz
4. Window 60s with 10s stride
5. Per-channel z-score normalization

Note: TUSZ may have malformed headers - fallback repair implemented. Channel synonyms handled (T7â†’T3, T8â†’T4, P7â†’T5, P8â†’T6).

## ğŸš€ Training Strategy

- Train: TUH EEG Seizure Corpus
- Validate: CHB-MIT
- Evaluate: epilepsybenchmarks.com
- No pretrained weights (novel architecture)

## âš ï¸ Critical Notes

- Caching keys depend on config; edit config to invalidate cache
- WSL tip: `export UV_LINK_MODE=copy` (Makefile sets this by default) âš™ï¸
- CI uses `uv sync` (no extras) to avoid GPU builds on non-CUDA runners
- Use `num_workers=0` in configs to prevent WSL multiprocessing hangs

---

**Mission**: Shock the world with O(N) clinical seizure detection ğŸš€