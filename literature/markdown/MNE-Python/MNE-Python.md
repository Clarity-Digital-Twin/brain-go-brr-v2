# MEG and EEG data analysis with MNE-Python

**Authors:** Alexandre Gramfort

**Subject:** Magnetoencephalography and electroencephalography (M/EEG) measure the weak electromagnetic signals generated by neuronal activity in the brain.

**Date:** D:20131228161845+05'30'

---

## Abstract

_[Abstract will be extracted from first pages]_

---


### Page 1

METHODS ARTICLE published: 26 December 2013 doi: 10.3389/fnins.2013.00267 MEG and EEG data analysis with MNE-Python Alexandre Gramfort1,2,3*, Martin Luessi2, Eric Larson4, Denis A. Engemann5,6, Daniel Strohmeier7, Christian Brodbeck8,R o m a nG o j9, Mainak Jas10,11, T eon Brooks8, Lauri Parkkonen10,11and Matti Hämäläinen2,11 1Institut Mines-Telecom, Telecom ParisTech, CNRS LTCI, Paris, France 2Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, and Harvard Medical School, Charlestown MA, USA 3NeuroSpin, CEA Saclay, Gif-sur-Yvette, France 4Institute for Learning and Brain Sciences, University of Washington, Seattle WA, USA 5Institute of Neuroscience and Medicine - Cognitive Neuroscience (INM-3), Forschungszentrum Juelich, Germany 6Brain Imaging Lab, Department of Psychiatry, University Hospital, Cologne, Germany 7Institute of Biomedical Engineering and Informatics, Ilmenau University of Technology, Ilmenau, Germany 8Department of Psychology, New Y ork University, New Y ork, NY , USA 9Psychological Imaging Laboratory, Psychology, School of Natural Sciences, University of Stirling, Stirling, UK 10Department of Biomedical Engineering and Computational Science, Aalto University School of Science, Espoo, Finland 11Brain Research Unit, O.V . Lounasmaa Laboratory, Aalto University School of Science, Espoo, Finland Edited by: Satrajit S. Ghosh, Massachusetts Institute of Technology, USA Reviewed by: Samuel Garcia, Université Claude Bernard Lyon I, France Forrest S. Bao, University of Akron, USA *Correspondence: Alexandre Gramfort, Institut Mines-Telecom, Telecom ParisTech, CNRS LTCI, 37-39 Rue Dareau,75014 Paris, France e-mail: alexandre.gramfort@ telecom-paristech.frMagnetoencephalography and electroencephalography (M/EEG) measure the weak electromagnetic signals generated by neuronal activity in the brain. Using these signalsto characterize and locate neural activation in the brain is a challenge that requires expertise in physics, signal processing, statistics, and numerical methods. As part of the MNE software suite, MNE-Python is an open-source software package that addressesthis challenge by providing state-of-the-art algorithms implemented in Python that cover multiple methods of data preprocessing, source localization, statistical analysis, and estimation of functional connectivity between distributed brain regions. All algorithmsand utility functions are implemented in a consistent manner with well-documented interfaces, enabling users to create M/EEG data analysis pipelines by writing Python scripts. Moreover, MNE-Python is tightly integrated with the core Python libraries forscientific comptutation (NumPy, SciPy) and visualization (matplotlib and Mayavi), as well as the greater neuroimaging ecosystem in Python via the Nibabel package. The code is provided under the new BSD license allowing code reuse, even in commercialproducts. Although MNE-Python has only been under heavy development for a couple of years, it has rapidly evolved with expanded analysis capabilities and pedagogical tutorials because multiple labs have collaborated during code development to help share best practices. MNE-Python also gives easy access to preprocessed datasets, helping users to get started quickly and facilitating reproducibility of methods by other researchers. Fulldocumentation, including dozens of examples, is available at http://martinos.org/mne. Keywords: electroencephalography (EEG), magnetoencephalography (MEG), neuroimaging, software, python, open-source 1. INTRODUCTION Magnetoencephalography (MEG) and electroencephalography (EEG) measure non-invasively the weak electromagnetic signalsinduced by neural currents. While the more common neuroimag-ing method of functional magnetic resonance imaging (fMRI)provides volumetric images defined over voxel grids using a sam-pling rate of around one image per second, M/EEG capturesboth slowly and rapidly changing dynamics of brain activationsat a millisecond time resolution. This enables the investigation of neuronal activity over a wide range of frequencies that canoffer potentially complementary insights regarding how the brainw o r k sa sal a r g es y s t e m( Tallon-Baudry et al., 1997; Fries, 2009). The processing and interpretation of M/EEG signals is, how- ever, challenging. While fMRI provides unambiguous localizationof the measured blood-oxygen-level dependent signal, estimatingthe neural currents underlying M/EEG is difficult. This complextask involves segmenting various structures from anatomicalMRIs, numerical solution of the electromagnetic forward prob-lem, signal denoising, a solution to the ill-posed electromagneticinverse problem, and appropriate statistical control. This com-plexity not only constitutes methodological challenges to MEGinvestigators, but also offers a great deal of flexibility in data anal-ysis. T o successfully process M/EEG data, a comprehensive andwell-documented analysis pipeline is therefore required. MNE-Python is a sub-project of the more general academic software package MNE ( Gramfort et al., 2013a ), whose goal is to implement and provide a set of algorithms allowing usersto assemble complete data analysis pipelines that encompassmost phases of M/EEG data processing. Several of such softwarepackages for M/EEG data processing exist, including Brainstorm(Tadel et al., 2011), EEGLAB [Delorme and Makeig (2004) and Delorme et al. (2011)], FieldTrip (Oostenveld et al., 2011), www.frontiersin.org December 2013 | Volume 7 | Article 267 |1 

---


### Page 2

Gramfort et al. MEG and EEG data analysis with MNE-Python NutMeg ( Dalal et al., 2011 )a n dS P M( Litvak et al., 2011 ). These other packages are implemented in MATLAB, with some depen-dencies on external packages such as OpenMEEG ( Gramfort et al., 2010b ) for boundary element method (BEM) forward mod- eling or NeuroFEM for volume based finite element method(FEM) ( Wolters et al., 2007 ) forward modeling. Many analysis methods are common to all these packages, yet MNE-Pythonoffers some unique capabilities, in a coherent package facilitatingthe combination of standard and advanced techniques in a singleenvironment described below. While MNE-Python is designed to integrate with packages within the Python community, it also seamlessly interfaces withthe other components of the MNE suite (and other M/EEG anal-ysis tools) because it uses the same Neuromag FIF file format,with consistent analysis steps and compatible intermediate files.MNE-Python and the related MNE-Matlab sub-package that shipwith MNE are both open source and distributed under the newBSD license, a.k.a 3-clause BSD, allowing their use in free aswell as commercial software. The MNE-Python code is the mostrecent addition to the MNE suite. After an intensive collaborativesoftware development effort, MNE-Python now provides a largenumber of additional features, such as time-frequency analysis,non-parametric statistics, connectivity estimation, independentcomponent analysis (ICA), and decoding, a.k.a. multivariate pat-tern analysis (MVPA) or simply supervised learning ,e a c ho fw h i c h is readily integrated into the standard MNE analysis pipeline. Thiscomprehensive and still growing set of features available in theMNE-Python package is made possible by a group of dedicatedcontributors coming from multiple institutions, countries, andresearch areas of expertise who collaborate closely. These inter-actions are facilitated by the use of an inclusive, highly interactivesoftware development process that is open for public viewing andcontribution. MNE-Python reimplements common M/EEG processing algo- rithms in pure Python. In addition, it also implements newalgorithms, proposed and only recently published by the MNE-Python authors, making them publicly available for the first time(Gramfort et al., 2010a, 2011, 2013b; Larson and Lee, 2013 ). T o achieve this task, MNE-Python is built on the foundationof core libraries provided by the scientific Python environment:NumPy (Van der Walt et al., 2011 ) offers the n-dimensional array data structure used to efficiently store and manipulate numeri-cal data; SciPy is used mainly for linear algebra, signal processing and sparse matrices manipulation; matplotlib (Hunter, 2007 )i s used for 2D graphics; Mayavi (Ramachandran and Varoquaux, 2010 ) is employed for 3D rendering; Scikit-Learn [Pedregosa et al. (2011 )a n d Buitinck et al. (2013 )] is required for decod- ing tasks; and the Python Data Analysis Library (Pandas) is used for interfacing with spreadsheet table oriented data processingtools as often used in econometrics and behavioral sciences.Mayavi ,Scikit-Learn and Pandas a r eo n l yr e q u i r e db yas m a l l subset of the code, and are therefore considered optional depen-dencies. Besides these general libraries, MNE-Python has someother optional dependencies on neuroimaging packages suchas Nibabel for reading and writing volume data (MRI, fMRI).T h eo n l i n ed o c u m e n t a t i o no fM N Ei sg e n e r a t e dw i t h Sphinx http://sphinx-doc .org.At present, MNE-Python contains more than 44,000 lines of Python code with around 22,000 lines of comments, contributedby a total of 35 persons. In this paper, we describe the MNE-Python package in detail, starting from the standard analysis pipeline to moreadvanced usage. With this work, we aim to help standard-ize M/EEG analysis pipelines, to foster collaborative soft-ware development between institutes around the world, andconsequently improve the reproducibility of M/EEG researchfindings. 2. THE MNE-PYTHON STANDARD WORKFLOW FOR M/EEG DATA ANALYSIS This section describes the standard analysis pipeline of MNE- Python. First, we discuss sample datasets that are available forworking with MNE-Python. They allow readers to follow alongwith the workflow and examples in this manuscript. We thenpresent the core Python structures employed in such an analysis,and use these to go from raw data preprocessing to the most com-monly used linear inverse methods. The full script correspondingto the steps described below is available at the end of this sectioninTa b l e 1 . 2.1. SAMPLE DATASETS The MNE software package provides a sample dataset consist- ing of recordings from one subject with combined MEG andEEG conducted at the Martinos Center of Massachusetts GeneralHospital. These data were acquired with a Neuromag VectorViewMEG system (Elekta Oy, Helsinki, Finland) with 306 sensorsarranged in 102 triplets, each comprising two orthogonal planargradiometers and one magnetometer. EEG was recorded simul-taneously with 60 electrodes. In the experiment, auditory stimuli(delivered monaurally to the left or right ear) and visual stim-uli (shown in the left or right visual hemifield) were presentedin a random sequence with a stimulus-onset asynchrony (SOA)of 750 ms. T o control for subject’s attention, a smiley face waspresented intermittently and the subject was asked to press abutton upon its appearance. These data are used in the MNE-Python package and in this manuscript for illustration purposes.Small samples from these data are also used in the MNE-Pythontest suite which guarantees reproducibility of results across sys-tems and environments, as well as the absence of regression whennew code is contributed. This sample dataset can also serve as astandard validation dataset for M/EEG methods, hence favoringreproducibility of results. For the same purpose, MNE-Pythonfacilitates easy access to the MEGSIM datasets ( Aine et al., 2012 ) that include both experimental and simulated MEG data. 2.2. DESIGN, APPLICATION PROGRAMMING INTERFACE (API) AND DATA STRUCTURES M/EEG data analysis typically involves three types of data con- tainers coded in MNE-Python as Raw ,Epochs ,a n d Evoked objects. The raw data comes straight out of the acquisition sys-tem; these can be segmented into pieces often called epochs ortrials, which generally correspond to segments of data after eachrepetition of a stimulus; these segments can be averaged to formevoked data. MNE-Python is designed to reproduce this standard Frontiers in Neuroscience | Brain Imaging Methods December 2013 | Volume 7 | Article 267 |2 

---


### Page 3

Gramfort et al. MEG and EEG data analysis with MNE-Python T able 1 | From raw data to dSPM source estimates in less than 30 lines of code. importmne # load data raw = mne.fiff.Raw( ’raw.fif’ ,preload=True) raw.info [ ’bads’] = [’MEG 2443’ , ’EEG 053’ ] #mark bad channels # low-pass filter data raw.filter (l_freq=None, h_freq=40.0) # extract epochs and save them picks = mne.fiff.pick_types (raw.info, meg=True, eeg=True, eog=True, exclude= ’bads’) events = mne.find_events (raw) epochs = mne.Epochs (raw, events, event_id=1, tmin= -0.2, tmax=0.5, proj=True, picks=picks, baseline=(None, 0), preload=True, reject=dict (grad=4000e -13, mag=4e -12, eog=150e -6)) # compute evoked response and noise covariance,and plot evoked evoked = epochs.average () cov = mne.compute_covariance (epochs, tmax=0) evoked.plot () # compute inverse operator fwd_fname = ’sample _audvis -meg-eeg-oct-6-fwd.fif’ fwd = mne.read_forward_solution(fwd_fname,surf_ori=True) inv = mne.minimum_norm.make_inverse_operator(raw.info, fwd, cov, loose=0.2) # compute inverse solution stc = mne.minimum_norm.apply_inverse(evoked, inv, lambda2=1./9., method= ’dSPM’) # morph it to average brain for group study and plot it stc_avg = mne.morph_data ( ’sample’ , ’fsaverage’ , stc, 5, smooth=5) stc_avg.plot () operating procedure by offering convenient objects that facilitate data transformation. Continuous raw data are stored in instances of the Raw class. MNE-Python supports reading raw data from various file formatse.g., BTI/4D, KIT, EDF, Biosemi BDF and BrainVision EEG. Otherformats such as eXimia or CTF can be converted to FIF files usingtools available in the MNE-C package, also available at http://martinos .org/mne. The Neo project (Garcia et al., under review) implements readers in Python for micromed and elan files, whichcan facilitate the use of these formats with MNE-Python. The FIFfile format allows organization of any type of information intoa multi-leaved tree structure of elements known as tags.I ti sa t the core of the MNE-Python package which favored the develop-ment of highly optimized reading and writing routines for thisformat. It offers for example the ability to read data from diskonly when needed. This access-on-demand principle can also beinherited by other classes that build upon Raw (such as Epochs andEvoked , below), which offers the possibility to process data with a very limited memory usage. Typical processing steps at thisstage include filtering, noise suppression (such as blinks or car-diac artifacts), data cropping, and visual data exploration. All ofthese are supported by convenient instance methods of the Raw class that will be explored in greater detail below. Typical M/EEG experiments involve presentation of stimuli and responses based on some form of task demands. The occur-rence of each stimulus or response can can be used to define anepoch which captures the brain signals preceding the stimulus orresponse as well as the response following them. Depending onthe experimental paradigm and the analysis employed, an epoch is typically 500 ms to 2 s long. Epochs of different experimentalconditions obtained from one subject are stored in MNE-Pythonin an instance of the Epochs class. An Epochs instance is created by specifying one or more instances of Raw to operate on, the event/stimulus type(s) of interest, and the time windowto include. The Epochs object has various parameters for pre- processing single trial data, such as baseline correction, signaldetrending, and temporal decimation. Epochs can be averaged toform evoked data containing the MEG and EEG signals knownrespectively as event related fields (ERFs) and event related poten-tials (ERPs). The averaged data are stored in instances of theEvoked class, and can be created simply by calling the average method on an instance of Epochs .A st h e Raw class, both Epochs andEvoked classes expose convenient plot methods that help visualizing single trials and evoked responses. Each of these data containers can be written to and read from disk using the FIF file format, which is readable fromthe MNE C code and the MNE-Matlab toolbox. These con-tainers share some common attributes such as ch_names , which is a Python list containing the names of all of thechannels, and an info attribute which is a modified Python dictionary storing all the metadata about the recordings. Thisattribute is commonly called the measurement information .F o r example, the sfreq key in the info dictionary, accessed with info[’sfreq’] syntax, is the sampling frequency; the chan- nel types and positions are available in info[’chs’] ;t h e positions of the head digitization points used for coregistration www.frontiersin.org December 2013 | Volume 7 | Article 267 |3 

---


### Page 4

Gramfort et al. MEG and EEG data analysis with MNE-Python are contained in info[’dig’] ;a n d info[’bads’] stores the list of bad channels. The info attribute can be used to conveniently do some channel selection by type (e.g., gradiome-ters, magnetometers, EEG), general position (e.g., right temporalchannels), or simply by channel names. These convenience func-tions in MNE-Python are known as pick functions, and they start with pick_ (e.g.,pick_types to select by channel type). Other standard data structures in MNE-Python handle forwardoperators, covariance matrices, independent components, andsource estimates. These structures will be introduced below afterexplaining their role in the standard pipeline. Importantly, theAPI follows as much as possible the Python standard libraryand the widely spread NumPy package. It avoids the prolif-eration of classes and limits the use of complex inheritancemechanisms. This helps to keep the code simple, favoring newcontributions. 2.3. PREPROCESSING The major goal when preprocessing data is to attenuate noiseand artifacts from exogenous (environmental) and endogenous(biological) sources. Noise reduction strategies generally fall intotwo broad categories: exclusion of contaminated data segmentsand attenuation of artifacts by use of signal-processing techniques(Gross et al., 2013 ). MNE-Python offers both options at differ- ent stages of the pipeline, through functions for automatic orsemi-automatic data preprocessing as well as interactive plottingcapabilities. The first preprocessing step often consists in restricting the signal to a frequency range of interest through filtering. MNE-Python supports band-pass, low-pass, high-pass, band-stop, andnotch filtering. Instances of Raw can be filtered using the filter method that supports fast Fourier transform (FFT) based finite impulse response (FIR) filters (optionally using theoverlap-add technique to minimize computation time), as wellas infinite impulse response (IIR) filters such as Butterworth fil-ters implemented in SciPy. Several channels can be filtered inparallel, thanks to the standard multiprocessing Python module exposed via the Joblib package (http://pythonhosted .org/joblib/).The FFTs used to implement FIR filters can also be efficiently computed on the graphical processing unit (GPU) via CUDA andPyCUDA ( Klöckner et al., 2012 ) ,f u r t h e rr e d u c i n gt h ee x e c u t i o n time. When segmenting continuous data into epochs, single epochs can be rejected based on visual inspection, or automaticallyby defining thresholds for peak-to-peak amplitude and flat sig-nal detection. The channels contributing to rejected epochs canalso be visualized to determine whether bad channels have beenmissed by visual inspection, or if noise rejection methods havebeen inadequate. Instead of simply excluding contaminated data from the anal- ysis, artifacts can sometimes be removed or significantly sup-pressed by using methods for signal decomposition such as signalspace projection (SSP; Uusitalo and Ilmoniemi, 1997 ) or inde- pendent component analysis (ICA, see Section 3.1 below). Theassumption behind the SSP method is that artifacts are confinedto a small-dimensional spatial subspace with specific topographicpatterns that are orthogonal or almost orthogonal to the brainsignal patterns of interest and can thus be suppressed with appro-priate projection vectors. Projection vectors can be derived frominstances of Raw as well as Epochs . MNE-Python also offers command-line level scripts and Python-level functions to auto-matically detect heart beats and eye blinks in the data, makingautomatic SSP computation possible. Once projection vectorsare specified for subtraction in the measurement info, MNEminimizes memory and disk space usage by not modifying theoriginal data but instead applying the projections on demand.This enables the user to explore the effects of particular SSPs laterin the pipeline and to selectively abandon some projection vectorsif the signals of interest are attenuated. After the above steps, onecan obtain clean data as illustrated in Figure 1 , which then can be further processed in epochs and evoked data, see Figure 2 . 2.4. LINEAR INVERSE METHODS After performing noise reduction via preprocessing, sensor-level data, especially those from planar gradiometers, may indicate theprobable number and approximate locations of active sources. FIGURE 1 | Noisy raw MEG magnetometer signals corrupted by a) slow drifts, b) line noise (at 50 or 60 Hz), and c) heartbeats present across sensors. To clean signals data were filtered between 1 and 45 Hz.Subsequently, five signal space projection (SSP) vectors were applied (3 computed from empty room noise, 2 from ECG signals). The plots were generated using the plot method of the Raw class. Frontiers in Neuroscience | Brain Imaging Methods December 2013 | Volume 7 | Article 267 |4 

---


### Page 5

Gramfort et al. MEG and EEG data analysis with MNE-Python In order to actually locate the sources, several different unique solutions to the ill-posed electromagnetic inverse problem exist.Each localization technique has its own modeling assumptionsa n dt h u sa l s os t r e n g t h sa n dl i m i t a t i o n s .T h e r e f o r e ,t h eM N Esoftware provides a selection of inverse modeling approaches.Importantly, in all of the approaches discussed here, the elemen-tary source employed is a current dipole, motivated by the phys-iological nature of the cerebral currents measurable in M/EEG(Hämäläinen et al., 1993 ). Different source modeling approaches are set apart by the selection constraints on the sources andother criteria to arrive at the best estimate for the cerebral current distribution as a function of time. Source localization methods generally fall into one of three categories: parametric overdetermined methods such as time- varying dipole fitting (Scherg and Von Cramon, 1985 ), scanning methods (including beamformers and the MUSIC algorithm),and distributed inverse methods. While MNE-Python does notprovide dipole-fitting functionality, it does implement multiplebeamformer methods and distributed inverse methods. The mostpopular of these is the software namesake MNE, which stands forMinimum-Norm Estimate ( Wang et al., 1992; Hämäläinen and Ilmoniemi, 1994 ), and its variants which include dSPM ( Dale et al., 2000 ) and sLORETA ( Pascual-Marqui, 2002 ). The standard MNE pipeline by uses MNE or dSPM as the inverse method by default. These methods employ the (weighted)/lscript 2-norm of the current distribution as regularizer. The impor- tant practical benefit of such /lscript2solvers is that the inverse problem is linear and, therefore, the solution is obtained by multiplyingthe data with a matrix, called the inverse operator .O n c et h e inverse operator has been constructed, it can be applied to evoked,epochs, and raw data containers. The output of these inversesolvers, as well as all alternative inverse methods, is provided asinstances of the SourceEstimate object that can be saved to disk as .stc files. The acronym stcstands for source times courses. The source estimates are defined on what is called a source space , which specifies the locations of the candidate dipole FIGURE 2 | An evoked response (event-related fields in planar gradiometers of an Elekta-Neuromag Vectorview system) showing traces for individual channels (bad channels are colored in red). Epochs with large peak-to-peak signals as well as channels marked as bad can bediscarded from further analyses. The figure was generated using the plot method of the Evoked class.sources, typically regularly sampled over the cortical mantle or on a volumetric grid. The source space routinely used by MNE isbased on the surface defined by the boundary between the grayand the white matter, which consists of a high-resolution meshwith over 100,000 vertices per hemisphere. T o reduce the numberof dipoles in the source space defined on this surface, it is neces-sary to decimate the mesh. However, preserving surface topology,spacing, and neighborhood information between neighboringvertices is difficult. Therefore, MNE uses a subsampling strategythat consists of polygon subdivisions using the spherical coordi-nate system provided by FreeSurfer. For example, an icosahedronsubdivided 5 times, abbreviated ico-5 , consists of 10242 loca- tions per hemisphere, which leads to an average spacing of 3.1 mmbetween dipoles (assuming a reasonable surface area of 1000 cm 2 per hemisphere), see illustration in Figure 3 . The source estimate defined on this low-resolution surface can then be up-sampledand represented on the original high-resolution cortical surfaceas presented in Figure 4 . FIGURE 3 | Cortical segmentation used for the source space in the distributed model with MNE. Left: The pial (red) and white matter (green) surfaces overlaid on an MRI slice. Right: The right-hemisphere part of the source space (yellow dots), represented on the inflated surface of the left hemisphere, was obtained by subdivision of an icosahedron leading to10242 locations per hemisphere with an average nearest-neighbor distance of 3.1 mm. Left image was produced with FreeSurfer tksurfer tool and the right one with PySurfer (http://pysurfer.github.io) which internally depends onMayavi (Ramachandran and Varoquaux, 2010 ). FIGURE 4 | Source localization of an auditory N100 component. Left: Results obtained using dSPM and a surface source space based on combined MEG and EEG data. The figure was generated using the plot method of the SourceEstimate class which internally calls PySurfer . Right: Results obtained using LCMV beamformer and a volume source space based on MEG channels only. The figure was generated using Freeview shipped with FreeSurfer. www.frontiersin.org December 2013 | Volume 7 | Article 267 |5 

---


### Page 6

Gramfort et al. MEG and EEG data analysis with MNE-Python 2.5. SURFACE-BASED NORMALIZATION While clinical examinations generally consider data from each patient separately, neuroscience questions are frequentlyanswered by comparing and combining data from groups of sub-jects. T o achieve this, data from all participating subjects needto be transformed to a common space in a manner that helpscompensate for inter-subject differences. This procedure, calledmorphing by the MNE software, exploits the FreeSurfer spherical coordinate system defined for each hemisphere ( Dale et al., 1999; Fischl et al., 1999 ). The process is illustrated in Figure 5 . 3. ADVANCED EXAMPLES Having described the standard MNE-Python workflow for source localization, we will now present some more advanced examplesof data processing. Some of these examples provide alternativeoptions for preprocessing and source localization. 3.1. DENOISING WITH INDEPENDENT COMPONENT ANALYSIS (ICA) In addition to SSP , MNE supports identifying artifacts andlatent components using temporal ICA. This method con-stitutes a latent variable model that estimates statisticallyindependent sources, based on distribution criteria such askurtosis or skewness. When applied to M/EEG data, artifactscan be removed by zeroing out the related independent com-ponents before inverse transforming the latent sources backinto the measurement space. The ICA algorithm currentlysupported by MNE-Python is FastICA ( Hyvärinen and Oja, 2000 ) implemented in Scikit-Learn (Pedregosa et al., 2011 ). Here, MNE-Python has added a domain specific set of conveniencefunctions covering visualization, automated component selec-tion, persistence as well as integration with the MNE-Pythonobject system. ICA in MNE-Python is handled by the ICA class which allows one to fit an unmixing matrix on eitherRaw orEpochs by calling the related decompose_raw ordecompose_epochs methods. After a model has been fitted, the resulting source time series can be visualized usingtrellis plots ( Becker et al., 1996 )( c f . Figure 6 )a sp r o v i d e db y theplot_sources_raw andplot_sources_epochs methods (illustrated in Figure 6 ). In addition, topographic plots depicting the spatial sensitivities of the unmixing matrixa r ep r o v i d e db yt h e plot_topomap method (illustrated in Figure 6 ). Importantly, the find_sources_raw and find_sources_epochs methods allow for identifying FIGURE 5 | Current estimates obtained from an individual subject can be remapped (morphed), i.e., normalized, to another corticalsurface, such as that of the FreeSurfer average brain “ fsaverage ” shown here. The normalization is done separably for both hemispheres using a non-linear registration procedure defined on the sphere ( Dale et al., 1999; Fischl et al., 1999 ). Here, the N100m auditory evoked response is localized using dSPM and then mappedto “fsaverage. ” Images were produced with PySurfer .sources based on bivariate measures, such as Pearson correlations with ECG recording, or simply based on univariate measuressuch as variance or kurtosis. The API, moreover, supports user-defined scoring measures. Identified source components can thenbe marked in the ICA object’s exclude attribute and saved into a FIF file, together with the unmixing matrix and runtime infor-mation. This supports a sustainable, demand-driven workflow:neither sources nor cleaned data need to be saved, signals canbe reconstructed from the saved ICA structure as required. Foradvanced use cases, sources can be exported as regular raw dataor epochs objects, and saved into FIF files ( sources_as_raw andsources_as_epochs ). This allows any MNE-Python analysis to be performed on the ICA time series. A simplifiedICA workflow for identifying, visualizing and removing cardiacartifacts is illustrated in Ta b l e 2 . 3.2. NON-PARAMETRIC CLUSTER-LEVEL STATISTICS For traditional cross-subject inferences, MNE-Python offers several parametric and non-parametric statistical methods.Parametric statistics provide valid statistical contrasts in so far asthe data under test conform to certain underlying assumptions ofGaussianity. The more general class of non-parametric statistics,which we will focus on here, do not require such assumptions tobe satisfied ( Nichols and Holmes, 2002; Pantazis et al., 2005 ). M/EEG data naturally contains spatial correlations, whether the signals are represented in sensor space or source space, astemporal patterns or time-frequency representations. Moreover,due to filtering and even the characteristics of the signals them-selves, there are typically strong temporal correlations as well.Mass univariate methods provide statistical contrasts at each“location” across all dimensions, e.g., at each spatio-temporalpoint in a cortical temporal pattern, independently. However, FIGURE 6 | T opographic and trellis plots of two automatically identified ICA components. The component #22 corresponds to the EOG artifact with a topography on the magnetometers showing frontal signals and a waveform typical of an eye blink. The c omponent #6 on the right captures the ECG artifact with a waveform matching 3 heart beats. Frontiers in Neuroscience | Brain Imaging Methods December 2013 | Volume 7 | Article 267 |6 

---


### Page 7

Gramfort et al. MEG and EEG data analysis with MNE-Python T able 2 | From epochs to ICA artifact removal in less than 20 lines of code. importmne from mne.datasets import sample import numpy as np # Setup paths and prepare data raw_fname = sample.data_path () + ’/MEG/sample/sample_audvis_filt -0-40_raw.fif’ raw = mne.fiff.Raw (raw_fname) picks = mne.fiff.pick_types (raw.info, meg= ’mag’, exclude= ’bads’) ica = mne.preprocessing.ICA (n_components=49) ica.decompose_raw (raw, picks=picks, decim=3) # use every third sample # find artifacts using bivariate and univariate measures scores = ica.find_sources_raw (raw, target= ’EOG 061’ , score_func= ’correlation’ ) ica.exclude += [scores.argmax ()] scores = ica.find_sources_raw (raw, score_func=np.var) ica.exclude += [scores.argmax ()] # Visualize result using topography and source time course ica.plot_topomap (ica.exclude)ica.plot_sources_raw (raw, ica.exclude, start=100., stop=103.) due to the highly correlated nature of the data, the resulting Bonferroni or false discovery rate corrections ( Benjamini and Hochberg, 1995 ) are generally overly conservative. Moreover, making inferences over individual spatio-temporal (or otherdimensional) points is typically not of principal interest. Instead,studies typically seek to identify contiguous regions withinsome particular dimensionality, be it spatio-temporal or time-frequency, during which activation is greater in one conditioncompared to a baseline or another condition. This leads tothe use of cluster-based statistics, which seek such contigu-ous regions of significant activation ( Maris and Oostenveld, 2007 ). MNE-Python includes a general framework for cluster-based tests to allow for performing arbitrary sets of contrasts alongarbitrary dimensions while controlling for multiple compar-isons. In practice, this means that the code is designed towork with many forms of data, whether they are stored asSourceEstimate for source-space data, or as Evoked for sensor-space data, or even as custom data formats, as neces-sary for time-frequency data. It can operate on any NumPy array using the natural (grid) connectivity structure, or a morecomplex connectivity structure (such as those in a brain sourcespace) with help of a sparse adjacency matrix. MNE-Python alsofacilitates the use of methods for variance control, such as the“hat” method ( Ridgway et al., 2012 ). Two common use cases are provided in Figure 7 . 3.3. DECODING—MVPA—SUPERVISED LEARNING MNE-Python can easily be used for decoding using Scikit- Learn (Pedregosa et al., 2011 ). Decoding is often referred to as multivariate pattern analysis (MVPA), or simply supervisedlearning. Figure 8 presents cross-validation scores in a binary classification task that consists of predicting, at each time point, ifan epoch corresponds to a visual flash in the left hemifield or a leftauditory stimulus. Results are presented in Figure 8 .T h es c r i p tt o reproduce this figure is available in Ta b l e 3 .3.4. FUNCTIONAL CONNECTIVITY Functional connectivity estimation aims to estimate the struc- ture and properties of the network describing the dependenciesbetween a number of locations in either sensor- or source-space. T o estimate connectivity from M/EEG data, MNE-Pythonemploys single-trial responses, which enables the detection ofrelationships between time series that are consistent across tri-als. Source-space connectivity estimation requires the use of aninverse method to obtain a source estimate for each trial. Whilecomputationally demanding, estimating connectivity in source-space has the advantage that the connectivity can be more readilyrelated to the underlying anatomy, which is difficult in the sensorspace. The connectivity module in MNE-Python supports a num- ber of bivariate spectral connectivity measures, i.e., connectivityis estimated by analyzing pairs of time series, and the connectiv-ity scores depend on the phase consistency across trials betweenthe time series at a given frequency. Examples of such mea-sures are coherence, imaginary coherence ( Nolte et al., 2004 ), and phase-locking value (PLV) ( Lachaux et al., 1999 ). The moti- vation for using imaginary coherence and related methods isthat they discard or downweight the contributions of the realpart of the cross spectrum and, therefore, zero-lag correlations,which can be largely a result of the spatial spread of the mea-sured signal or source estimate distributions ( Schoffelen and Gross, 2009 ). However, note that even though some methods can suppress the effects of the spatial spread, connectivity esti-mates should be interpreted with caution; due to the bivariatenature of the supported measures, there can be a large num-ber of apparent connections due to a latent region connectingor driving two regions that both contribute to the measureddata. Multivariate connectivity measures, such as partial coher-ence ( Granger and Hatanaka, 1964 ), can alleviate this problem by analyzing the connectivity between all regions simultaneously (cf.Schelter et al., 2006 ). We plan to add support for such measures in the future. www.frontiersin.org December 2013 | Volume 7 | Article 267 |7 

---


### Page 8

Gramfort et al. MEG and EEG data analysis with MNE-Python FIGURE 7 | Examples of clustering. (A) Time-frequency clustering showing a significant region of activation following an auditory stimulus. (B)A visualization of the significant spatio-temporal activations in a contrastbetween auditory stimulation and visual stimulation using the sample dataset. The red regions were more active after auditory than after visual stimulation, and vice-versa for blue regions. Image (B)was produced with PySurfer . FIGURE 8 | Sensor space decoding. At every time instant, a linear support vector machine (SVM) classifier is used with a cross-validation loop to test if one can distinguish data following a stimulus in the left ear or in the left visual field. One can observe that the two conditions start to be significantly differentiated as early as 50 ms and maximally at 100 ms whichcorresponds to the peak of the primary auditory response. Such a statistical procedure is a quick and easy way to see in which time window the effect of interest occurs. The connectivity estimation routines in MNE-Python are designed to be flexible yet computationally efficient. Whenestimating connectivity in sensor-space, an instance of Epochs is used as input to the connectivity estimation routine. Forsource-space connectivity estimation, a Python list containingSourceEstimate instances is used. Instead of a list, it is also possible to use a Python generator object which producesSourceEstimate instances. This option drastically reduces the memory requirements, as the data is read on-demandfrom the raw file and projected to source-space during theconnectivity computation, therefore requiring only a singleSourceEstimate instance to be kept in memory. T o use this feature, inverse methods which operate on Epochs , e.g., apply_inverse_epochs ,h a v et h eo p t i o nt or e t u r na generator object instead of a list. For linear inverse methods,e.g., MNE, dSPM, sLORETA, further computational savings areachieved by storing the inverse kernel and sensor-space data intheSourceEstimate objects, which allows the connectivity estimation routine to exploit the linearity of the operations andapply the time-frequency transforms before projecting the datato source-space. Due to the large number of time series, connectivity estimation between all pairs of time series in source-space is computation-ally demanding. T o alleviate this problem, the user has the optionto specify pairs of signals for which connectivity should be esti-mated, which makes it possible, for example, to compute theconnectivity between a seed location and the rest of the brain. Forall-to-all connectivity estimation in source-space, an attractiveoption is also to reduce the number of time series, and thus thecomputational demand, by summarizing the source time serieswithin a set of cortical regions. We provide functions to do thisautomatically for cortical parcel lations obtained by FreeSurfer, which employs probabilistic atlases and cortical folding patternsfor an automated subject-specific segmentation of the cortexinto anatomical regions ( Fischl et al., 2004; Desikan et al., 2006; Destrieux et al., 2010 ). The obtained set of summary time series can then be used as input to the connectivity estimation. Theassociation of time series with cortical regions simplifies theinterpretation of results and it makes them directly compara-ble across subjects since, due to the subject-specific parcellation,each time series corresponds to the same anatomical region ineach subject. Code to compute the connectivity between thelabels corresponding to the 68 cortical regions in the FreeSurfer“aparc” parcellation is shown in Ta b l e 4 and the results are shown inFigure 9 . 3.5. BEAMFORMERS MNE-Python implements two source localization techniques based on beamforming: Linearly-Constrained MinimumVariance (LCMV) in the time domain ( Van Veen et al., 1997 ) and Dynamic Imaging of Coherent Sources (DICS) in thefrequency domain ( Gross et al., 2001 ). Beamformers construct adaptive spatial filters for each location in the source spacegiven a data covariance (or cross-spectral density in DICS). Thisleads to pseudo-images of “source power” that one can store asSourceEstimates . Figure 4 presents example results of applying the LCMV beamformer to the sample data set for comparison with resultsachieved using dSPM. The code that was used to generate thise x a m p l ei sl i s t e di n Ta b l e 5 . Frontiers in Neuroscience | Brain Imaging Methods December 2013 | Volume 7 | Article 267 |8 

---


### Page 9

Gramfort et al. MEG and EEG data analysis with MNE-Python T able 3 | Sensor space decoding of MEG data. importmne from sklearn.svm import SVC from sklearn.cross_validation import cross_val_score, ShuffleSplit # Take only the data channels (here the gradiometers) data_picks = mne.fiff.pick_types (epochs1.info, meg= ’grad’, exclude= ’bads’) # Make arrays X and y such that: # X is 3d with X.shape[0] is the total number of epochs to classify # y is filled with integers coding for the class to predict # We must have X.shape[0] equal to y.shape[0] X = [e.get_data () [:, data_picks, :] for e in (epochs1, epochs2)] y = [k * np.ones (len(this_X)) for k, this_X in enumerate(X)] X = np.concatenate(X) y = np.concatenate(y) clf = SVC(C=1, kernel= ’linear’ ) # Define a monte-carlo cross-validation generator (to reduce variance): cv = ShuffleSplit (len(X), 10, test_size=0.2) scores, std_scores = np.empty (X.shape[2]), np.empty (X.shape[2]) for t in xrange(X.shape[2]): Xt = X[:, :, t] scores_t = cross_val_score(clf, Xt, y, cv=cv, n_jobs=1) scores [t] = scores_t.mean () std_scores [t] = scores_t.std () T able 4 | Connectivity estimation between cortical regions in the source space. importmne from mne.minimum_norm i mport apply_inverse_epochs from mne.connectivity import spectral_connectivity # Apply inverse to single epochs stcs = apply_inverse_epochs (epochs, inverse_op, lambda2, method= ’dSPM’, pick_normal=True, return_generator=True) # Summarize souce estimates in labels labels, label_colors = mne.labels_from_parc ( ’sample’ , parc=’aparc’, subjects_dir=subjects_dir) label_ts = mne.extract_label_time_course (stcs, labels, inverse_op [ ’src’], mode= ’mean_flip’ , return_generator=True) # Compute all-to-all connectivity between labels con, freqs, times, n_epochs, n_tapers = spectral_connectivity (label_ts, method=’wpli2_debiased’ , mode=’multitaper’ , sfreq=raw.info[ ’sfreq’], fmin=8., fmax=13., faverage=True, mt_adaptive=True) 3.6. NON-LINEAR INVERSE METHODS All the source estimation strategies presented thus far, from MNE to dSPM or beamformers, lead to linear transforms ofsensor-space data to obtain source estimates. There are alsomultiple inverse approaches that yield non-linear source esti-mation procedures. Such methods have in common to promotespatially sparse estimates. In other words, source configurationsconsisting of a small set of dipoles are favored to explain thedata. `MNE-Python implements three of these approaches, namelymixed-norm estimates (MxNE) ( Gramfort et al., 2012 ), time- frequency mixed-norm estimates (TF-MxNE) ( Gramfort et al., 2013b ) that regularize the estimates in a time-frequency repre- sentation of the source signals, and a sparse Bayesian learningtechnique named γ-MAP ( Wipf and Nagarajan, 2009 ).` `Source localization results obtained on the ERF evoked by the left visualstimulus with both TF-MxNE and γ-MAP are presented in Figure 10 . 4.` DISCUSSION Data processing, such as M/EEG analysis, can be thought of as a sequence of operations, where each step has an impacton the subsequent (and ultimately final) results. In the pre-ceding sections we have first detailed the steps of the standardMNE pipeline, followed by the presentation of some alterna-tive and complementary analysis tools made available by thepackage. MNE-Python is a scripting-based package with many visu- alization capabilities for visualizing results of processing stepsand final outputs, but limited graphical user interfaces (GUIs)for actually performing processing steps. Leveraging the good www.frontiersin.org December 2013 | Volume 7 | Article 267 |9 

---


### Page 10

Gramfort et al. MEG and EEG data analysis with MNE-Python FIGURE 9 | Connectivity between brain regions of interests, also called labels, extracted from the automatic FreeSurfer parcellation visualizedusing plot_connectivity_circle .The image of the right presentsthese labels on the inflated cortical surface. The colors are in agreement between both figures. Left image was produced with matplotlib and right image with PySurfer . T able 5 | Inverse modeling using the LCMV beamformer. import mne # load raw data and create epochs and evoked objects as in Table 1, but pickin g # only MEG channels using mne.fiff.pick_types(raw.info, meg=True, eeg=False) # compute noise and data covariance noise_cov = mne.compute_covariance(epochs, tmax=0.0) noise_cov = mne.cov.regularize (noise_cov, evoked.info, mag=0.05, grad=0.05, eeg=0.1, proj=True) data_cov = mne.compute_covariance (epochs, tmin=0.04, tmax=0.15) # compute LCMV inverse solution fwd_fname = ’sample_audvis -meg-vol-7-fwd.fif’ fwd = mne.read_forward_solution (fwd_fname, surf_ori=True) stc = mne.beamformer.lcmv(evoked, fwd, noise_cov, data_cov, reg=0.1, pick_ori= ’max -power’) # save result in 4D nifti file for plotting with Freesurfer stc.save_as_volume( ’lcmv.nii.gz’ , fwd[’src’], mri_resolution=False) readability on the Python language, particular care has been taken to keep the scripts simple, easy to read and to write.This is similar in spirit with the FieldTrip package ( Oostenveld et al., 2011 ), in that it pushes users toward standardizing anal- yses via scripting instead of processing data in a GUI. Perhapsthe largest downside of this scripting approach is that usersclearly need to be able to write reasonable scripts. Howeverthis approach, which is facilitated by many examples thatcan be copied from the MNE website, has very clear bene-fits. First, our experience from analyzing several M/EEG stud-ies unambiguously indicates that the processing pipeline mustbe tailored for each study based on the equipment used, thenature of the experiment, and the hypotheses under test. Eventhough most pipelines follow the same general logic (filter- ing, epoching, averaging, etc.), the number of options is largeeven for such standard steps. Scripting gives the flexibility toset those options once per study to handle the requirementsof different M/EEG studies. Second, analyses conducted withhelp of documented scripts lead to more reproducible resultsand ultimately help improve the quality of the research results.Finally, studies that involve processing of data from dozens orhundreds of subjects are made tractable via scripting. This isparticularly relevant in an era of large-scale data analysis withpossibly more than a thousand subjects, cf., the Human Brain Project or the Human Connectome Project ( Van Essen et al., 2012 ). Frontiers in Neuroscience | Brain Imaging Methods December 2013 | Volume 7 | Article 267 |10 

---


### Page 11

Gramfort et al. MEG and EEG data analysis with MNE-Python FIGURE 10 | Source localization with non-linear sparse solvers. `The left plot shows results from TF -MxNE on raw unfiltered data (due to the built-in temporal smoothing), and the right plot shows results from γ-MAP on the same data but filtered below 40 Hz.` One can observe the agreement between both methods on the sources in the primary (red) and secondary (yellow) visual cortices delineated by FreeSurfer using an atlas. `The γ-MAP identifies two additional sources in the right fusiform gyrus along the visual ventral stream.` These sources that would not be naturally expected fromsuch simple visual stimuli are weak and peak later in time, which makes them nevertheless plausible. Software-based data analysis is not limited to neuroimaging, and the fact today is that neuroscientists from different academicdisciplines spend an increasing amount of time writing softwareto process their experimental data. We would wager that almostall scientific data are ultimately processed with computers soft-ware. The practical consequence of this is that the quality ofthe science produced relies on the quality of the software writ-ten ( Dubois, 2005 ). The success of digital data analysis is made possible not just by acquiring high-quality data and sometimesby using sophisticated numerical and mathematical methods, butcritically it is made possible by using correct implementations ofmethods. The MNE-Python project is developed and maintainedto help provide the best quality in terms of accuracy, efficiency,and readability. In order to preserve analysis accuracy, the devel-opment process requires the writing of unit and regression tests(so-called test-driven development) that ensure that the soft-ware is installed and functioning correctly, yielding results thatmatch those previously obtained from many different users andmachines. This testing framework currently covers about 86%of the lines of MNE-Python code, which not only enhances thequality and stability of the software but also makes it easier toincorporate new contributions quickly without breaking exist-ing code. Code quality is also improved by a peer review process among the developers. Any code contribution must be read byat least two people, the author and a reviewer, in order to miti-gate the risk of errors. Moreover, the entire source code and fulldevelopment history is made publicly available by a distributedversion control system. This makes it possible to keep track ofthe development of the project and handle code changes in a waythat minimizes the risk of rendering existing scripts and anal-ysis pipelines inoperable. Finally, large parts of the source codeare commented using inline documentation that allows for auto-matically building user manuals in PDF and HTML formats.The Ohloh.net 1source code analysis project attests that 35% of the source code consists of documentation and with this, MNE-Python scores in the upper third of the most well documentedPython projects. Some recent studies have pointed out the heterogeneity of functional MRI data analysis pipelines ( Carp, 2012a,b ). These studies quantify the combinatorial explosion of analysis optionswhen many different steps are combined as required when ana-lyzing neuroimaging data. Although they focused on fMRI, thesame issue arises for M/EEG. We argue that this fact does notneed to become a significant drawback, as long as the detailsrequired to make the analysis reproducible are available. A dif-ficulty does arise in that whatever level of detail is provided in amethods section of a paper, it is ultimately unlikely to be suffi-cient to provide access to all parameters used. However, sharingthe proper code provides a better guarantee for reproducible sci-ence. The previously mentioned studies also raise the issue thatthe geographical location of the investigators biases their choice interms of method and software. Again, this is not wrong per se ,a s expertise is more easily found from colleagues than mailing listsor user documentation. By favoring on-line collaborative workbetween international institutions, MNE-Python aims to reducethis geographical bias. While an important goal in science is the reproducibility of results, reproducibility can have two levels of meaning. Rerunningthe same analysis (code) on the same dataset using the samemachine should always be possible. However, we should really beaiming for a deeper level of reproducability that helps foster newscientific discoveries, namely where rerunning the same analysison data collected on an equivalent task in another laboratory. Inother words, analysis pipelines should ideally be reusable acrosslaboratories. Although it is often overlooked by users (and somedevelopers), care must be taken regarding the license governinguse of a given software package in order to maximize its impact.The MNE-Python code is thus provided under the very permis-sive open source new BSD license. This license allows anybody toreuse and redistribute the code, even in commercial applications. Neuroimaging is a broad field encompassing static images, such as anatomical MRI as well as dynamic, functional data suchas M/EEG or fMRI. The MNE software already relies on someother packages such as FreeSurfer for anatomical MRI process-ing, or Nibabel for file operations. Our ambition is of course notto make MNE-Python self-contained, dropping any dependencyon other software. Indeed the MNE-Python package cannot anddoes not aim to do everything. MNE has its own scope and seeksto leverage the capabilities of external software in the neuroimag-ing software ecosystem. Tighter integration with fMRI analysispipelines could be facilitated by NiPype ( Gorgolewski et al., 2011 ) but is first made possible by adopting standards. That is why alldata MNE produces are stored in FIF file format which can beread and written by various software packages written in differ-ent languages. The MNE-Python code favors its integration in thescientific Python ecosystem via the use of NumPy and SciPy ,a n d limits effort duplication and code maintainance burden by push-ing to more general purpose software packages any improvement 1http://www.ohloh.net/p/MNE. www.frontiersin.org December 2013 | Volume 7 | Article 267 |11 

---


### Page 12

Gramfort et al. MEG and EEG data analysis with MNE-Python to non M/EEG specific algorithms. For example, improvement of ICA code were contributed back to Scikit-Learn , as it could be for signal processing routines in the scipy.signal module. Good science requires not only good hypotheses and theories, creative experimental design, and principled analysis methods,but also well-established data analysis tools and software. TheMNE-Python software provides a solid foundation for repro-ducible scientific discoveries based on M/EEG data. Throughthe contributions and feedback from a diverse set of M/EEGresearchers, it should provide increasing value to the neuroimag-ing community. ACKNOWLEDGMENTS We would like to thank the many members of the M/EEGcommunity who have contributed through code, comments,and even complaints, to the improvement and design of thispackage. FUNDING This work was supported by National Institute of BiomedicalImaging and Bioengineering grants 5R01EB009048 andP41RR014075, National Institute on Deafness and OtherCommunication Disorders fellowship F32DC012456, and NSFawards 0958669 and 1042134. The work of Alexandre Gramfortwas partially supported by ERC-YStG-263584. Martin Luessi waspartially supported by the Swiss National Science FoundationEarly Postdoc. Mobility fellowship 148485. Christian Brodbeckwas supported by grant G1001 from the NYUAD Institute.T eon Brooks was supported by the National Science FoundationGraduate Research Fellowship under Grant No. DGE-1342536.Lauri Parkkonen was supported by the “aivoAALTO” program.Daniel Strohmeier was supported by grant Ha 2899/8-2 from theGerman Research Foundation. 
## References

MEG-SIM: a web portal for testing MEG analysis methods using realistic simulated and empirical data. Neuroinformatics 10, 141-158. doi: 10.1007/s12021-011-9132-z Becker, R. A., Cleveland, W. S., Shyu, M.-J., and Kaluzny, S. 
### P . (1996).

AT o u ro f Trellis Graphics . T echnical Report, Bell Laboratories. Benjamini, Y., and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. J. R. Stat. Soc. Ser. B 57, 289-300. doi: 10.1016/j.neuroimage.2012.07.004 Buitinck, L., Louppe, G., Blondel, M., Pedregosa, F., Mueller, A., Grisel, O., et al. (2013). “API design for machine learning software: experi-ences from the scikit-learn project,” in European Conference on Machine Learning and Principles and Practices of Knowledge Discovery in Databases , Prague. Carp, J. (2012a). On the plurality of (methodological) worlds: estimating the analytic flexibility of fMRI experiments. Front. Neurosci. 6:149. doi: 10.3389/fnins.2012.00149 Carp, J. (2012b). The secret lives of experiments: methods reporting in the fMRI literature. Neuroimage 63, 289-300. doi: 10.1016/j.neuroimage.2012.07.004 Dalal, S. S., Zumer, J. M., Guggisberg, A. G., Trumpis, M., Wong, D. D. E., Sekihara, K., et al. (2011). MEG/EEG source reconstruction, statistical evalu-ation, and visualization with NUTMEG. Comput. Intell. Neurosci. 2011:758973. doi: 10.1155/2011/758973 Dale, A., Fischl, B., and Sereno, M. (1999). Cortical surface-based analysis i: segmentation and surface reconstruction. Neuroimage 9, 179-194. doi: 10.1006/nimg.1998.0395Dale, A., Liu, A., Fischl, B., and Buckner, R. (2000). Dynamic statistical parametric mapping: combining fMRI and MEG for high-resolution imaging of cortical activity. Neuron 26, 55-67. doi: 10.1016/S0896-6273(00)81138-1 Delorme, A., and Makeig, S. (2004). EEGLAB: an open source toolbox for analy- sis of single-trial EEG dynamics including independent component analysis. J. Neurosci. Methods 134, 9-21. doi: 10.1016/j.jneumeth.2003.10.009 Delorme, A., Mullen, T., Kothe, C., Acar, Z. A., Bigdely-Shamlo, N., Vankov, A., et al. (2011). EEGLAB, SIFT, NFT, BCILAB, and ERICA: new tools for advanced EEG processing. Intell. Neurosci. 2011:130714. doi: 10.1155/2011/130714 Desikan, R. S., Ségonne, F., Fischl, B., Quinn, B. T., Dickerson, B. C., Blacker, D., et al. (2006). An automated labeling system for subdividing the human cere- bral cortex on MRI scans into gyral based regions of interest. Neuroimage 31, 968-980. doi: 10.1016/j.neuroimage.2006.01.021 Destrieux, C., Fischl, B., Dale, A., and Halgren, E. (2010). Automatic parcella- tion of human cortical gyri and sulci using standard anatomical nomenclature. Neuroimage 53:1. doi: 10.1016/j.neuroimage.2010.06.010 Dubois, P . (2005). Maintaining correctness in scientific programs. Comput. Sci. Eng. 7, 80-85. doi: 10.1109/MCSE.2005.54 Fischl, B., Sereno, M., and Dale, A. (1999). Cortical surface-based analysis ii: infla- tion, flattening, and a surface-based coordinate system. Neuroimage 9, 195-207. doi: 10.1006/nimg.1998.0396 Fischl, B., Van Der Kouwe, A., Destrieux, C., Halgren, E., Ségonne, F., Salat, D. H., et al. (2004). Automatically parcellating the human cerebral cortex. Cereb. Cortex 14, 11-22. doi: 10.1093/cercor/bhg087 Fries, P . (2009). Neuronal gamma-band synchronization as a fundamental process in cortical computation. Annu. Rev. Neurosci. 32, 209-224. doi: 10.1146/annurev.neuro.051508.135603 Gorgolewski, K., Burns, C. D., Madison, C., Clark, D., Halchenko, Y. O., Waskom, M. L., et al. (2011). Nipype: a flexible, lightweight and extensible neuroimag- ing data processing framework in python. Front. Neuroinform. 5:13. doi: 10.3389/fninf.2011.00013 Gramfort, A., Keriven, R., and Clerc, M. (2010a). Graph-based variability estima- tion in single-trial event-related neural responses. IEEE Trans. Biomed. Eng. 57, 1051-1061. doi: 10.1109/TBME.2009.2037139 Gramfort, A., Papadopoulo, T., Olivi, E., and Clerc, M. (2010b). OpenMEEG: open- source software for quasistatic bioelectromagnetics. BioMed Eng. OnLine 9:45. doi: 10.1186/1475-925X-9-45 Gramfort, A., Kowalski, M., and Hämäläinen, M. (2012). Mixed-norm estimates for the M/EEG inverse problem using accelerated gradient methods. Phys. Med. Biol. 57, 1937-1961. doi: 10.1088/0031-9155/57/7/1937 Gramfort, A., Luessi, M., Larson, E., Engemann, D., Strohmeier, D., Brodbeck, C., et al. (2013a). MNE software for processing MEG and EEG data. Neuroimage doi: 10.1016/j.neuroimage.2013.10.027. (in press). Available online at: http://www.sciencedirect.com/science/article/pii/S1053811913010501 Gramfort, A., Strohmeier, D., Haueisen, J., Hämäläinen, M., and Kowalski, M. (2013b). Time-frequency mixed-norm estimates: sparse M/EEG imag- ing with non-stationary source activations. Neuroimage 70, 410-422. doi: 10.1016/j.neuroimage.2012.12.051 Gramfort, A., Strohmeier, D., Haueisen, J., Hämäläinen, M., and Kowalski, M. (2011). “Functional brain imaging with M/EEG using structured sparsity in time-frequency dictionaries,” in Information Processing in Medical Imaging Vol. 6801 of Lecture Notes in Computer Science , eds G. Székely and H. Hahn (Heidelberg; Berlin: Springer), 600-611. Granger, C. W. J., and Hatanaka, M. (1964). Spectral Analysis of Economic Time Series . Princeton, NJ: Princeton University Press. Gross, J., Baillet, S., Barnes, G., Henson, R., Hillebrand, A., Jensen, O., et al. (2013). Good practice for conducting and reporting MEG research. Neuroimage 65, 349-363. doi: 10.1016/j.neuroimage.2012.10.001 Gross, J., Kujala, J., Hamalainen, M., Timmermann, L., Schnitzler, A., and Salmelin, R. (2001). Dynamic imaging of coherent sources: Studying neural interac- tions in the human brain. Proc. Natl. Acad. Sci. U.S.A. 98, 694-699. doi: 10.1073/pnas.98.2.694 Hämäläinen, M., Hari, R., Ilmoniemi, R., Knuutila, J., and Lounasmaa, O. (1993). Magnetoencephalography - Theory, instrumentation, and applications to non- invasive studies of the working human brain. Rev. Modern Phys. 65, 413-497. doi: 10.1103/RevModPhys.65.413 Hämäläinen, M., and Ilmoniemi, R. (1994). Interpreting magnetic fields of the brain: minimum norm estimates. Med. Biol. Eng. Comput. 32, 35-42. doi: 10.1007/BF02512476 Frontiers in Neuroscience | Brain Imaging Methods December 2013 | Volume 7 | Article 267 |12 

---


### Page 13

Gramfort et al. MEG and EEG data analysis with MNE-Python Hunter, J. D. (2007). Matplotlib: a 2d graphics environment. Comput. Sci. Eng. 9, 90-95. doi: 10.1109/MCSE.2007.55 Hyvärinen, A., and Oja, E. (2000). Independent component analysis: algorithms and applications. Neural networks 13, 411-430. doi: 10.1016/S0893-6080(00) 00026-5 Klöckner, A., Pinto, N., Lee, Y., Catanzaro, B., Ivanov, P ., and Fasih, A. (2012). PyCUDA and PyOpenCL: a scripting-based approach to GPU run- time code generation. Parallel Comput. 38, 157-174. doi: 10.1016/j.parco. 2011.09.001 Lachaux, J.-P ., Rodriguez, E., Martinerie, J., and Varela, F. J. (1999). Measuring phase synchrony in brain signals. Hum. Brain Mapp. 8, 194-208. doi: 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C Larson, E., and Lee, A. K. C. (2013). The cortical dynamics underlying effec- tive switching of auditory spatial attention. Neuroimage 64, 365-370. doi: 10.1016/j.neuroimage.2012.09.006 Litvak, V ., Mattout, J., Kiebel, S., Phillips, C., Henson, R., Kilner, J., et al. (2011). EEG and MEG data analysis in SPM8. Comput. Intell. Neurosci. 2011:852961. doi: 10.1155/2011/852961 Maris, E., and Oostenveld, R. (2007). Nonparametric statistical test- ing of EEG- and MEG-data. J. Neurosci. Methods 164, 177-190. doi: 10.1016/j.jneumeth.2007.03.024 Nichols, T. E., and Holmes, A. 
### P . (2002).

Nonparametric permutation tests for func- tional neuroimaging: a primer with examples. Hum. Brain Mapp. 15, 1-25. doi: 10.1002/hbm.1058 Nolte, G., Bai, O., Wheaton, L., Mari, Z., Vorbach, S., and Hallett, M. (2004). Identifying true brain interaction from eeg data using the imaginary part of coherency. Clin. Neurophysiol. 115, 2292-2307. doi: 10.1016/j.clinph.2004.04.029 Oostenveld, R., Fries, P ., Maris, E., and Schoffelen, J.-M. (2011). Field trip: open source software for advanced analysis of MEG, EEG, and invasive electrophysi-ological data. Comput. Intell. Neurosci. 2011:156869. doi: 10.1155/2011/156869 Pantazis, D., Nichols, T. E., Baillet, S., and Leahy, R. M. (2005). A comparison of random field theory and permutation methods for the statistical analysis of MEG data. Neuroimage 25, 383-394. doi: 10.1016/j.neuroimage.2004.09.040 Pascual-Marqui, R. (2002). Standardized low resolution brain elec- tromagnetic tomography (sLORETA): technical details. Methods Find. Exp. Clin. Pharmacology 24, 5-12. Available online at: http://www.ncbi.nlm.nih.gov/pubmed/12575463 Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V ., Thirion, B., Grisel, O., et al. (2011). Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825-2830. Available online at: http://jmlr.org/papers/v12/pedregosa11a.html Ramachandran, P ., and Varoquaux, G. (2010). Mayavi: a package for 3d visualiza- tion of scientific data. Comput. Sci. Eng. 13, 40-51. doi: 10.1109/MCSE.2011.35 Ridgway, G. R., Litvak, V ., Flandin, G., Friston, K. J., and Penny, W. D. (2012). The problem of low variance voxels in statistical parametric map- ping; a new hat avoids a “haircut.” Neuroimage 59, 2131-2141. doi: 10.1016/j.neuroimage.2011.10.027 Schelter, B., Winterhalder, M., and Timmer, J. (2006). Handbook of Time Series Analysis . Weinheim: Wiley-VCH. Scherg, M., and Von Cramon, D. (1985). Two bilateral sources of the late AEP as identified by a spatio-temporal dipole model. Electroencephalogr. Clin. Neurophysiol. 62, 32-44. doi: 10.1016/0168-5597(85)90033-4Schoffelen, J.-M., and Gross, J. (2009). Source connectivity analysis with MEG and EEG. Hum. Brain Mapp. 30, 1857-1865. doi: 10.1002/hbm.20745 Tadel, F., Baillet, S., Mosher, J. C., Pantazis, D., and Leahy, R. M. (2011). Brainstorm: a user-friendly application for MEG/EEG analysis. Comput. Intell. Neurosci. 2011:879716. doi: 10.1155/2011/879716 Tallon-Baudry, C., Bertrand, O., Wienbruch, C., Ross, B., and Pantev, C. (1997). Combined EEG and MEG recordings of visual 40 hz responses to illusory trian- gles in human. Neuroreport NA, 1103-1107. doi: 10.1097/00001756-199703240- 00008 Uusitalo, M., and Ilmoniemi, R. (1997). Signal-space projection method for sep- arating MEG or EEG into components. M e d .B i o l .E n g .C o m p u t . 35, 135-140. doi: 10.1007/BF02534144 Van der Walt, S., Colbert, S., and Varoquaux, G. (2011). The NumPy array: a structure for efficient numerical computation. Comp. Sci. Eng. 13, 22-30. doi: 10.1109/MCSE.2011.37 Van Essen, D., Ugurbil, K., Auerbach, E., Barch, D., Behrens, T., Bucholz, R., et al. (2012). The human connectome project: A data acquisition perspective.Neuroimage 62, 2222-2231. doi: 10.1016/j.neuroimage.2012.02.018 Van Veen, B., van Drongelen, W., Yuchtman, M., and Suzuki, A. (1997). Localization of brain electrical activity via linearly constrained minimum variance spatial filtering. IEEE Trans. Biomed. Eng. 44, 867-880. doi: 10.1109/10.623056 Wang, J.-Z., Williamson, S. J., and Kaufman, L. (1992). Magnetic source images determined by a lead-field analysis: the unique minimum-norm least-squares estimation. IEEE Trans. Biomed. Eng. 39, 665-675. doi: 10.1109/10.142641 Wipf, D., and Nagarajan, S. (2009). A unified Bayesian framework for MEG/EEG source imaging. Neuroimage 44, 947-966. doi: 10.1016/j.neuroimage.2008.02.059 Wolters, C. H., Köstler, H., Möller, C., Härdtlein, J., Grasedyck, L., and Hackbusch, W. (2007). Numerical mathematics of the subtraction method for the modelingof a current dipole in EEG source reconstruction using finite element head models. SIAM J. Sci. Comput. 30, 24-45. doi: 10.1137/060659053 Conflict of Interest Statement: The authors declare that the research was con- ducted in the absence of any commercial or financial relationships that could beconstrued as a potential conflict of interest. Received: 27 September 2013; accepted: 09 December 2013; published online: 26 December 2013. Citation: Gramfort A, Luessi M, Larson E, Engemann DA, Strohmeier D, Brodbeck C,Goj R, Jas M, Brooks T, Parkkonen L and Hämäläinen M (2013) MEG and EEG data analysis with MNE-Python. Front. Neurosci. 7:267. doi: 10.3389/fnins.2013.00267 This article was submitted to Brain Imaging Methods, a section of the journal Frontiersin Neuroscience. Copyright © 2013 Gramfort, Luessi, Larson, Engemann, Strohmeier, Brodbeck, Goj, Jas, Brooks, Parkkonen and Hämäläinen. This is an open-access article dis- tributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, providedthe original author(s) or licensor are credited and that the original publica- tion in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. www.frontiersin.org December 2013 | Volume 7 | Article 267 |13 

---


## Conversion Notes

- **Source PDF:** `MNE-Python.pdf`
- **Total Pages:** 13
- **Converted with:** PyPDF2
- **Note:** This is an automated conversion. Some formatting, equations, and figures may not be perfectly preserved.
