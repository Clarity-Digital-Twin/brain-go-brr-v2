# ðŸŽ¯ CANONICAL ARCHITECTURE ROADMAP

## WHERE WE ARE NOW (v2.0 - BASELINE)
```
EEG (19ch, 256Hz) â†’ U-Net â†’ ResCNN â†’ Bi-Mamba-2 â†’ Detection Head
```
**Status**: SHIPPED & TRAINING on Modal
**Performance**: TBD (currently training)
**Cost**: ~$0.80/epoch on Modal

---

## INCREMENTAL UPGRADES (Ship & Train Each)

### v2.1 - Multi-Task Artifact Suppression âš¡
```
EEG â†’ U-Net â†’ ResCNN â†’ Bi-Mamba-2 â†’ [Seizure Head + Artifact Head]
```
**Changes**: Add artifact detection head (TUAR dataset)
**Why**: Reduce false alarms from muscle/eye/electrode artifacts
**Expected**: 30-50% FA reduction (proven in literature)
**Timeline**: 1 week
**Training**: Co-train on TUSZ + TUAR

### v2.2 - Frequency Domain Input ðŸ“Š
```
EEG â†’ STFT â†’ U-Net â†’ ResCNN â†’ Bi-Mamba-2 â†’ Detection Head
```
**Changes**: Add Short-Time Fourier Transform preprocessing
**Why**: EvoBrain paper shows frequency domain captures seizure markers better
**Expected**: 5-10% sensitivity improvement
**Timeline**: 3 days
**Training**: Same TUSZ, different input representation

### v2.5 - Add GNN for Spatial Reasoning ðŸ§ 
```
EEG â†’ U-Net â†’ ResCNN â†’ Bi-Mamba-2 â†’ GNN â†’ Detection Head
                                          â†‘
                                    ADD THIS!
```
**Changes**: Add Graph Neural Network after Mamba
**Status**: Planned (not implemented)
**Implementation Details** (from EvoBrain):
- Use SSGConv (Simple Spectral Graph) or GCNConv
- Edge weights from correlation matrix
- Skip connections around GNN
**Why**: Learn electrode relationships, montage-agnostic
**Expected**: 10-15% cross-dataset transfer improvement
**Timeline**: 1 week
**Training**: Same data, spatial awareness added

### v2.6 - Dynamic Graphs + Laplacian PE ðŸ”„
```
EEG â†’ U-Net â†’ ResCNN â†’ Bi-Mamba-2 â†’ [LPE + Dynamic GNN] â†’ Detection Head
```
**Changes**: GNN with time-evolving adjacency + Laplacian Positional Encoding
**Status**: Planned (not implemented)
**Implementation Details** (from EvoBrain):
- PyG's `AddLaplacianEigenvectorPE(k=16)`
- Adjacency matrix per timestep: `adj[timestep, batch, nodes, nodes]`
- Concatenate PE to node features before GNN
- Edge pruning: keep only |weight| > 0.0001
**Why**: EvoBrain proves dynamic > static graphs; LPE stabilizes
**Expected**: Additional 5-10% improvement
**Timeline**: 1 week
**Training**: Graph structure evolves per snapshot

---

## MAJOR REPLACEMENTS (One at a Time)

### v3.0 - Replace U-Net with TCN ðŸš€
```
EEG â†’ TCN â†’ ResCNN â†’ Bi-Mamba-2 â†’ GNN â†’ Detection Head
       â†‘
  REPLACE U-Net
```
**Changes**: Temporal Convolutional Network replaces U-Net
**Why**: Simpler, native 1D design, proven superior for sequences
**Expected**: Faster training, comparable performance
**Timeline**: 2 weeks
**Training**: Full retrain required

---

## Implementation Hooks
- Wire graph stage after Mamba:
  - `src/brain_brr/models/detector.py:104`
- New GNN module (planned):
  - `src/brain_brr/models/gnn.py` (GraphChannelMixer)
- Channel ordering source of truth:
  - `src/brain_brr/constants.py:12`
- Dependency: PyTorch Geometric required for LPE/GCN (to be added later)

### v3.1 - Replace ResCNN with ConvNeXt ðŸŽ¯
```
EEG â†’ TCN â†’ ConvNeXt â†’ Bi-Mamba-2 â†’ GNN â†’ Detection Head
              â†‘
         REPLACE ResCNN
```
**Changes**: Modern ConvNeXt blocks
**Why**: 2022 architecture > 2015 ResNet
**Expected**: 5-10% performance gain
**Timeline**: 1 week
**Training**: Retrain from v3.0

### v3.2 - Dual-Stream Mamba ðŸŒŠ
```
EEG â†’ TCN â†’ ConvNeXt â†’ [Node-Mamba + Edge-Mamba] â†’ GNN â†’ Detection Head
                                â†‘
                          DUAL STREAM
```
**Changes**: Separate Mamba for nodes and edges (EvoBrain style)
**Implementation Details** (from EvoBrain):
- Node-Mamba: `Mamba(d_model=512, d_state=16, d_conv=4, expand=2)`
- Edge-Mamba: Same config, processes edge features
- Both outputs fed to GNN
**Why**: Model channel features and relationships separately
**Expected**: 10-15% improvement
**Timeline**: 2 weeks
**Training**: More complex but powerful

---

## EXPERIMENTAL (High Risk/Reward)

### v4.0 - Full EvoBrain-Inspired Stack
```
EEG â†’ STFT â†’ [TCN-Nodes + TCN-Edges] â†’ GCN+LPE â†’ Detection Head
```
**Changes**: Full time-then-graph with dual temporal streams
**Why**: Mathematically proven optimal expressivity
**Expected**: 20-30% total improvement
**Timeline**: 1 month
**Training**: Complete architecture overhaul

---

## TRAINING STRATEGY PER VERSION

1. **Train baseline (v2.0)** â†’ Get TAES metrics
2. **Add one change** â†’ Train â†’ Compare metrics
3. **If better**: Keep and build on it
4. **If worse**: Revert and try next idea
5. **Document everything**: Params, FLOPs, FA/24h, sensitivity

## SUCCESS METRICS (Track for Each Version)

| Version | FA/24h@90% | Params | GFLOPs | Modal $/epoch | Notes |
|---------|------------|--------|--------|---------------|-------|
| v2.0    | BASELINE   | 47M    | TBD    | $0.80         | Current |
| v2.1    | Target -30%| +2M    | +0.1   | $0.85         | Artifact head |
| v2.2    | Target -5% | Same   | +0.5   | $0.85         | STFT input |
| v2.5    | Target -10%| +5M    | +2.0   | $0.90         | Add GNN |
| v3.0    | Target same| -10M   | -5.0   | $0.70         | TCN simpler |
| v3.1    | Target -5% | +2M    | +1.0   | $0.75         | ConvNeXt |
| v3.2    | Target -10%| +15M   | +3.0   | $0.95         | Dual Mamba |

---

## IMMEDIATE NEXT STEPS (THIS WEEK)

1. âœ… **Let v2.0 finish training** (baseline metrics)
2. ðŸ”§ **Implement v2.1** (artifact head) - HIGHEST ROI
3. ðŸ“Š **Test v2.2** (STFT) - Easy win
4. ðŸ§  **Prototype v2.5** (add GNN) - Validated by EvoBrain

---

## KEY INSIGHTS FROM EVOBRAIN (Sep 2025)

âœ… **Time-then-graph > Graph-then-time** (mathematically proven)
âœ… **Dynamic graphs > Static graphs** (explicit modeling wins)
âœ… **Frequency domain helps** (STFT preprocessing)
âœ… **Laplacian Positional Encoding** (k=16 eigenvectors optimal)
âœ… **Dual-stream temporal** (separate node/edge Mamba streams)
âœ… **SSGConv performs best** for EEG graphs
âœ… **Our Mamba (time) â†’ GNN (graph) ordering is CORRECT!**

### Concrete Implementation Params from EvoBrain:
- Mamba: `d_state=16, d_conv=4, expand=2`
- GNN: 2-layer SSGConv with skip connections
- LPE: 16 eigenvectors
- Activation: Tanh for GNN, Softplus for edge weights

---

## DECISION TREE

```
v2.0 (current) working?
â”œâ”€ YES â†’ Add artifact head (v2.1)
â”‚   â”œâ”€ Better? â†’ Add STFT (v2.2)
â”‚   â”‚   â”œâ”€ Better? â†’ Add GNN (v2.5)
â”‚   â”‚   â”‚   â”œâ”€ Better? â†’ Replace U-Net with TCN (v3.0)
â”‚   â”‚   â”‚   â””â”€ Worse? â†’ Try dynamic GNN (v2.6)
â”‚   â”‚   â””â”€ Worse? â†’ Skip to GNN (v2.5)
â”‚   â””â”€ Worse? â†’ Debug why artifacts hurt
â””â”€ NO â†’ Fix v2.0 first!
```

---

**PHILOSOPHY**: Ship small, train often, measure everything. Each version should be a working system we can deploy.

**Last Updated**: 2025-09-22
**Next Review**: After v2.0 baseline metrics available
