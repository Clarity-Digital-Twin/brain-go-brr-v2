# ğŸ§  Brain-Go-Brr V3: Clinical EEG Seizure Detection

**State-of-the-art seizure detection using TCN + BiMamba + GNN with Dynamic Laplacian PE**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://python.org)
[![PyTorch 2.2.2](https://img.shields.io/badge/pytorch-2.2.2-red.svg)](https://pytorch.org)
[![CUDA 12.1](https://img.shields.io/badge/cuda-12.1-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-yellow.svg)](LICENSE)

## ğŸš€ Highlights

- **O(N) Complexity**: Linear-time processing via Mamba state-space models
- **Dual-Stream Architecture**: Parallel processing of node (19Ã—) and edge (171Ã—) features
- **Dynamic Graph Learning**: Time-evolving brain connectivity without heuristics
- **NaN-Robust Training**: 3-tier clamping system with gradient sanitization
- **31M Parameters**: Efficient architecture that runs on consumer GPUs

## ğŸ“Š Clinical Performance Targets

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ False Alarms    â”‚ Sensitivity  â”‚ Status      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 10 FA/24h       â”‚ >95%         â”‚ ğŸ”„ Training â”‚
â”‚ 5 FA/24h        â”‚ >90%         â”‚ ğŸ”„ Training â”‚
â”‚ 1 FA/24h        â”‚ >75%         â”‚ ğŸ¯ Target   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Current Status**: Building cache (4667/6499 files) â†’ Ready to train

## ğŸ—ï¸ Architecture

```
                    EEG Input (19 channels @ 256Hz)
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ TCN ENCODER  â”‚ 8 layers, strideâ†“16
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                     â•”â•â•â•â•â•â•§â•â•â•â•â•â•—
                     â•‘ PROJECTION â•‘ 512 â†’ 19Ã—64
                     â•šâ•â•â•â•â•â•¤â•â•â•â•â•â•
                     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                     â–¼           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚NODE MAMBA  â”‚ â”‚EDGE MAMBA  â”‚  Parallel
              â”‚  19Ã—SSM    â”‚ â”‚  171Ã—SSM   â”‚  Streams
              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”‚               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  GNN + LPE   â”‚ Dynamic PE
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   DECODER    â”‚ Upsampleâ†‘16
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     Seizure Predictions
```

### Key Components

| Component | Description | Parameters |
|-----------|-------------|------------|
| **TCN** | 8-layer temporal encoder with dilated convolutions | 12.8M |
| **BiMamba** | Bidirectional state-space model (6 layers) | 8.4M |
| **GNN** | 2-layer SSGConv with Î±=0.05 for EEG graphs | 6.2M |
| **Dynamic LPE** | k=16 eigenvectors, computed per timestep | 4.1M |
| **Total** | End-to-end trainable | **31.5M** |

## âš¡ Quick Start

### Prerequisites

```bash
# System requirements
- Ubuntu 20.04+ or WSL2
- CUDA 12.1+ with cuDNN 8.9+
- 24GB+ GPU memory (RTX 4090 or better)
- 32GB+ system RAM
```

### Installation

```bash
# 1. Install UV package manager (faster than pip)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2. Clone and setup environment
git clone https://github.com/clarity-digital-twin/brain-go-brr-v2.git
cd brain-go-brr-v2
make setup

# 3. Install GPU components (CRITICAL: exact versions matter!)
make setup-gpu  # Installs mamba-ssm==2.2.2, PyG, TCN
```

### Data Preparation

```bash
# Download TUH EEG Seizure Corpus (requires agreement)
# Place in: data_ext4/tusz/edf/

# Build preprocessed cache (one-time, ~6 hours)
python -m src build-cache \
  --data-dir data_ext4/tusz/edf \
  --cache-dir cache/tusz

# Expected output:
# âœ… 4667 train files (306GB)
# âœ… 1832 dev files (143GB)
```

### Training

```bash
# Quick smoke test (5 minutes)
make s

# Full local training (RTX 4090)
export BGB_SANITIZE_GRADS=1  # Recommended for stability
tmux new -s train
make train-local
# Ctrl+B, D to detach
# tmux attach -t train to resume

# Cloud training (Modal A100)
modal run --detach deploy/modal/app.py \
  --action train \
  --config configs/modal/train.yaml
```

## ğŸ”§ Configuration

### Critical Settings

```yaml
# RTX 4090 (24GB) - configs/local/train.yaml
training:
  batch_size: 12        # Memory-optimized
  mixed_precision: false  # MUST be false (causes NaNs)
  gradient_clip: 0.1     # Aggressive for stability

model:
  graph:
    use_dynamic_pe: true       # Enable dynamic PE
    semi_dynamic_interval: 5   # Update every 5 timesteps (memory tradeoff)

# A100 (80GB) - configs/modal/train.yaml
training:
  batch_size: 64
  mixed_precision: true   # A100 handles FP16 safely
  gradient_clip: 0.5
```

### Environment Variables

```bash
# Debugging
export BGB_NAN_DEBUG=1        # Verbose NaN reporting
export BGB_SANITIZE_GRADS=1   # Clean gradients (RECOMMENDED)
export BGB_DEBUG_FINITE=1     # Check all tensors

# Performance
export BGB_LIMIT_FILES=50     # Limit data for testing
export BGB_SMOKE_TEST=1       # Quick validation mode
```

## ğŸ“ Project Structure

```
brain-go-brr-v2/
â”œâ”€â”€ src/brain_brr/
â”‚   â”œâ”€â”€ models/          # Core architecture
â”‚   â”‚   â”œâ”€â”€ detector.py  # Main model orchestrator
â”‚   â”‚   â”œâ”€â”€ tcn.py      # Temporal convolutions
â”‚   â”‚   â”œâ”€â”€ mamba.py    # Bidirectional SSM
â”‚   â”‚   â””â”€â”€ gnn_pyg.py  # Graph neural network
â”‚   â”œâ”€â”€ data/           # Preprocessing pipeline
â”‚   â”œâ”€â”€ train/          # Training loop
â”‚   â””â”€â”€ post/           # Post-processing
â”œâ”€â”€ configs/            # Training configurations
â”œâ”€â”€ tests/              # Comprehensive test suite
â”œâ”€â”€ docs/               # Documentation
â”‚   â”œâ”€â”€ 00-overview/    # Architecture & targets
â”‚   â”œâ”€â”€ 03-configuration/  # Config validation
â”‚   â”œâ”€â”€ 04-model/       # Component details
â”‚   â”œâ”€â”€ 05-training/    # Training guides
â”‚   â””â”€â”€ 08-operations/  # Troubleshooting
â””â”€â”€ cache/tusz/         # Preprocessed data
```

## ğŸ› ï¸ Development

### Essential Commands

```bash
make q          # Run quality checks (lint, format, type)
make t          # Fast test suite
make test       # Full tests with coverage
make clean      # Clean all artifacts
```

### Monitoring Training

```bash
# Local monitoring
tensorboard --logdir results/
watch -n 1 nvidia-smi  # GPU usage

# Modal monitoring
modal app list         # List running apps
modal app logs <id>   # Stream logs
```

### Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| NaN losses | Enable `BGB_SANITIZE_GRADS=1` and rebuild cache |
| OOM errors | Reduce batch_size or increase semi_dynamic_interval |
| Slow training | Verify cache on SSD, not network mount |
| Import errors | Exact versions: torch==2.2.2, mamba-ssm==2.2.2 |

## ğŸ“Š Expected Performance

### Training Time Estimates

| Hardware | Batch Size | Time/Epoch | Total Time | Cost |
|----------|------------|------------|------------|------|
| RTX 4090 | 12 | ~2-3 hours | ~200-300h | Power |
| A100-80GB | 64 | ~1 hour | ~100h | ~$319 |

### Memory Requirements

| Component | RTX 4090 | A100 | Note |
|-----------|----------|------|------|
| Model | 4GB | 4GB | Fixed |
| Batch | 8GB | 32GB | Scales with batch_size |
| Dynamic PE | 4GB | 8GB | Scales with interval |
| **Total** | **16GB** | **44GB** | Expected peak |

## ğŸ“š Documentation

### Must Read
- [CLAUDE.md](CLAUDE.md) - Project context for AI assistants
- [ARCHITECTURE_EVOLUTION.md](ARCHITECTURE_EVOLUTION.md) - Design decisions
- [docs/08-operations/nan-prevention-complete.md](docs/08-operations/nan-prevention-complete.md) - NaN handling

### Deep Dives
- [docs/04-model/v3-architecture.md](docs/04-model/v3-architecture.md) - Full architecture
- [docs/04-model/laplacian-pe.md](docs/04-model/laplacian-pe.md) - Dynamic PE math
- [docs/05-training/modal-deployment.md](docs/05-training/modal-deployment.md) - Cloud setup

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Run `make q` before committing
4. Add tests for new features
5. Submit a pull request

## ğŸ“ˆ Roadmap

- [x] V3 dual-stream architecture
- [x] Dynamic Laplacian PE
- [x] NaN-robust training
- [ ] <1 FA/24h performance
- [ ] Real-time inference optimization
- [ ] Multi-dataset validation
- [ ] Clinical deployment

## ğŸ“ Citation

```bibtex
@software{brain-go-brr-v3,
  title = {Brain-Go-Brr V3: Clinical EEG Seizure Detection},
  author = {Clarity Digital Twin},
  year = {2025},
  url = {https://github.com/clarity-digital-twin/brain-go-brr-v2}
}
```

## ğŸ“„ License

Apache 2.0 - See [LICENSE](LICENSE)

## ğŸ™ Acknowledgments

- **TUH EEG Seizure Corpus** - Temple University Hospital
- **CHB-MIT** - Children's Hospital Boston & MIT
- **Modal.com** - Cloud GPU infrastructure
- **Mamba** - Gu & Dao for SSM architecture
- **PyG Team** - PyTorch Geometric library

---

<div align="center">
<b>Questions?</b> Open an issue | <b>Updates:</b> Watch the repo | <b>Discussion:</b> Start a discussion
</div>