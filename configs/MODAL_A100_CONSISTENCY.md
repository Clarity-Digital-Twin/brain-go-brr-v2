# MODAL A100 CONFIG CONSISTENCY VERIFICATION ✅

## FIXES APPLIED

### 1. train_a100.yaml
- ✅ Changed `device: auto` → `cuda` (explicit GPU for consistency)

### 2. dev_a100.yaml
- ✅ Fixed checkpoint path: `/results/tusz_a100_100ep/checkpoints/best.pt`

### 3. eval_a100.yaml
- ✅ Fixed checkpoint path: `/results/tusz_a100_100ep/checkpoints/best.pt`

## A100-OPTIMIZED SETTINGS (ALL CONFIGS)

### GPU-Optimized Data Loading:
```yaml
num_workers: 8              # A100 can handle parallel loading
pin_memory: true            # Fast GPU transfer
persistent_workers: true    # Reuse workers (unlike WSL2!)
prefetch_factor: 4          # Pre-load batches
```

### A100 80GB VRAM Batch Sizes:
| Config | Batch Size | Purpose |
|--------|------------|---------|
| train_a100.yaml | 64 | Training (8x larger than local) |
| smoke_a100.yaml | 64 | Quick test |
| dev_a100.yaml | 128 | Inference (2x training) |
| eval_a100.yaml | 128 | Inference (2x training) |

### Model & Architecture (IDENTICAL across all):
```yaml
model:
  name: seizure_detector
  mamba:
    n_layers: 6
    d_model: 512
    d_state: 16
  # ... identical to local configs
```

### Modal-Specific Paths:
```yaml
data:
  data_dir: /data/edf/{split}          # S3 mount
  cache_dir: /results/cache/{purpose}  # Persistent volume
experiment:
  output_dir: /results/{purpose}       # Persistent volume
```

## CHECKPOINT FLOW (MODAL)

1. **train_a100.yaml** → Creates `/results/tusz_a100_100ep/checkpoints/best.pt`
2. **dev_a100.yaml** → Loads from `/results/tusz_a100_100ep/checkpoints/best.pt`
3. **eval_a100.yaml** → Loads from `/results/tusz_a100_100ep/checkpoints/best.pt`

## KEY DIFFERENCES FROM LOCAL

| Setting | Local (RTX 4090) | Modal (A100-80GB) |
|---------|------------------|-------------------|
| num_workers | 0 (WSL2 issues) | 8 (Linux optimized) |
| pin_memory | false | true |
| persistent_workers | false | true |
| batch_size (train) | 8 | 64 (8x larger) |
| batch_size (eval) | 32 | 128 (4x larger) |
| gradient_accumulation | Not needed | 1 (large batches) |
| save_predictions | false | true (cloud storage) |
| save_plots | false | true (cloud storage) |

## VALIDATION

All Modal A100 configs are now:
- ✅ A100-optimized (8 workers, pin_memory, large batches)
- ✅ Internally consistent (same model, preprocessing, postprocessing)
- ✅ Properly linked (checkpoint paths match)
- ✅ Cloud-optimized (S3 data, persistent volumes)
- ✅ GPU-explicit (device: cuda)

## SPECIAL MODAL FEATURES

1. **Tensor Cores**: `mixed_precision: true` for A100 speedup
2. **Large Batches**: 64-128 batch size (vs 8-32 local)
3. **Parallel Loading**: 8 workers (vs 0 local)
4. **W&B Integration**: All configs have W&B enabled
5. **Save Everything**: predictions & plots (cloud has space)

Ready for Modal cloud training!