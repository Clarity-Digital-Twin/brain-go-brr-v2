# Modal A100 Smoke Test: TCN + Bi-Mamba + GNN Stack (v2 or v3)
# Quick validation (1 epoch) on Modal A100-80GB
#
# NOTE: app.py automatically sets BGB_LIMIT_FILES=50 for smoke tests
# This limits to 50 files instead of full 3734 for quick validation
#
# Usage: modal run deploy/modal/app.py --action train --config configs/modal/smoke.yaml
data:
  dataset: tuh_eeg
  data_dir: /data/edf                   # Parent dir containing train/dev/eval
  cache_dir: /results/cache/tusz       # Persistent SSD cache (NOT S3!)
  split_policy: official_tusz          # Use TUSZ official patient-disjoint splits
  sampling_rate: 256
  n_channels: 19
  window_size: 60
  stride: 10
  num_workers: 8                       # A100 needs parallel loading
  pin_memory: true                     # A100 optimized
  persistent_workers: true              # A100 optimized
  prefetch_factor: 4
  use_balanced_sampling: false         # Must be false for BGB_LIMIT_FILES to work

preprocessing:
  montage: "10-20"
  bandpass: [0.5, 120]
  notch_freq: 60
  normalize: true

model:
  # Architecture: "tcn" (v2) or "v3" (dual-stream with edge Mamba)
  architecture: v3  # Change to "tcn" for v2 path

  tcn:
    num_layers: 8
    kernel_size: 7
    dropout: 0.15
    causal: false
    stride_down: 16
    use_cuda_optimizations: true

  mamba:
    n_layers: 6
    d_model: 512
    d_state: 16
    conv_kernel: 4  # CUDA constraint: must be 2-4
    dropout: 0.1

  # Graph configuration (works for both v2 and v3)
  graph:
    enabled: true              # Required for both v2.6 and v3

    # V3-specific: Edge stream config (ignored when architecture="tcn")
    edge_features: cosine      # Edge feature metric for v3
    edge_top_k: 3              # Top-k edges per node for v3
    edge_threshold: 1.0e-4     # Edge weight cutoff for v3
    edge_mamba_layers: 2       # Edge Mamba layers for v3
    edge_mamba_d_state: 8      # Edge Mamba state dim for v3
    edge_mamba_d_model: 16     # Edge Mamba model dim (learned lift 1→16→1)

    # V2 heuristic removed

    # Shared GNN architecture (both v2.6 and v3)
    n_layers: 2                # 2-layer GNN
    dropout: 0.1
    use_residual: true         # Skip connections
    alpha: 0.05                # SSGConv mixing
    k_eigenvectors: 16         # Laplacian PE dimension

    # Dynamic PE config (v3) - ALWAYS ENABLED
    use_dynamic_pe: true       # ALWAYS use dynamic PE (EvoBrain approach)
    semi_dynamic_interval: 1   # Update PE every N timesteps (1=fully dynamic)
    pe_sign_consistency: true  # Fix eigenvector signs for stability

postprocessing:
  hysteresis:
    tau_on: 0.86
    tau_off: 0.78
  morphology:
    opening_kernel: 11
    closing_kernel: 31
  duration:
    min_duration_s: 3.0
    max_duration_s: 600.0
  events:
    tau_merge: 2.0
    confidence_method: mean

training:
  epochs: 1                            # Just 1 epoch for smoke test
  batch_size: 32                       # Reduced for v3 dual-stream memory
  loss: focal
  focal_alpha: 0.5
  focal_gamma: 2.0
  learning_rate: 5e-5                  # Reduced from 3e-4 for NaN stability
  weight_decay: 0.05
  optimizer: adamw
  scheduler:
    type: cosine
    warmup_ratio: 0.03
  gradient_clip: 0.5                   # Stronger clipping for NaN protection
  mixed_precision: true                # A100 is 3.8x faster at FP16!

evaluation:
  metrics: [taes, sensitivity, specificity, auroc]
  fa_rates: [10, 5, 2.5, 1]

experiment:
  name: smoke_test
  description: "Stack smoke test on Modal A100"
  seed: 42
  device: cuda
  output_dir: /results/smoke
  cache_dir: /results/cache/tusz
  log_level: INFO
  save_model: false
  # BGB_LIMIT_FILES set automatically in app.py for smoke configs
  wandb:
    enabled: true
    project: seizure-detection-smoke
    entity: jj-vcmcswaggins-novamindnyc  # Your W&B TEAM (matches API key)
    tags: ["smoke-test", "modal", "a100", "v3"]

logging:
  log_every_n_steps: 10
