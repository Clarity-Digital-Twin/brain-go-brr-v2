# TUSZ Dev Set - Hyperparameter Tuning ONLY
# Use this AFTER training to tune thresholds and hyperparameters

data:
  dataset: tuh_eeg
  data_dir: data_ext4/tusz/edf/dev   # DEV SET - 55 patients for tuning
  sampling_rate: 256
  n_channels: 19
  window_size: 60
  stride: 10
  num_workers: 0                        # WSL2-safe: avoid multiprocessing hangs
  pin_memory: false                      # WSL2-safe: prevent /dev/shm issues
  persistent_workers: false              # WSL2-safe: critical for stability
  validation_split: 0.0                  # No split - use entire dev set
  use_balanced_sampling: true           # CRITICAL: Use positive-aware sampling

preprocessing:
  montage: "10-20"
  bandpass: [0.5, 120]
  notch_freq: 60
  normalize: true
  use_mne: true

model:
  architecture: tcn  # Use TCN instead of U-Net

  tcn:
    num_layers: 8
    channels: [64, 128, 256, 512]
    kernel_size: 7
    dilation_base: 2
    dropout: 0.1

  mamba:
    n_layers: 6
    d_model: 512
    d_state: 16
    conv_kernel: 4
    dropout: 0.1

postprocessing:
  hysteresis:
    tau_on: 0.86      # TUNE THESE ON DEV SET
    tau_off: 0.78     # TUNE THESE ON DEV SET
  morphology:
    opening_kernel: 11
    closing_kernel: 31
  duration:
    min_duration_s: 3.0
    max_duration_s: 600.0
  events:
    tau_merge: 2.0
    confidence_method: mean

training:
  epochs: 0  # NO TRAINING - evaluation only
  batch_size: 32
  mixed_precision: true

evaluation:
  metrics: [taes, sensitivity, specificity, auroc]
  fa_rates: [10, 5, 2.5, 1]
  mode: tuning  # Special mode for hyperparameter search

experiment:
  name: tusz_dev_tuning_$(date +%Y%m%d_%H%M%S)
  description: "Hyperparameter tuning on TUSZ dev set"
  seed: 42
  device: cuda                          # REQUIRED: Must use CUDA
  output_dir: results/tuning
  cache_dir: cache/dev_tuning
  log_level: INFO
  checkpoint_path: results/tcn_full_100ep/checkpoints/best.pt  # Load trained TCN model

logging:
  log_every_n_steps: 50
  tensorboard: true