# PR-1: Smoke test with boundary normalization enabled
# Based on smoke.yaml but with normalization at component boundaries

experiment:
  name: smoke_test_pr1
  description: "PR-1 boundary normalization smoke test"
  seed: 42
  output_dir: results/smoke_pr1
  device: cuda

model:
  architecture: v3  # V3 dual-stream with learned adjacency

  tcn:
    num_layers: 8
    kernel_size: 7
    dropout: 0.15
    causal: false
    stride_down: 16
    use_cuda_optimizations: true

  mamba:
    n_layers: 6
    d_model: 512
    d_state: 16
    conv_kernel: 4  # CUDA constraint: must be 2-4
    dropout: 0.1

  # Graph configuration
  graph:
    enabled: true
    edge_features: cosine
    edge_top_k: 3
    edge_threshold: 1.0e-4
    edge_mamba_layers: 2
    edge_mamba_d_state: 8
    edge_mamba_d_model: 16
    n_layers: 2
    dropout: 0.1
    use_residual: true
    alpha: 0.05
    k_eigenvectors: 16
    use_dynamic_pe: true  # Re-enabled with memory fixes
    semi_dynamic_interval: 10
    pe_sign_consistency: true

  # PR-1: BOUNDARY NORMALIZATION CONFIGURATION
  norms:
    boundary_norm: layernorm  # Type of norm: layernorm | rmsnorm | none
    boundary_eps: 1.0e-5  # Epsilon for numerical stability
    layerscale_alpha: 0.1  # Initial LayerScale value (from Touvron et al. 2021)

    # Fine-grained control over norm locations
    after_tcn_proj: true  # Normalize after TCN projection to electrodes
    after_node_mamba: true  # Normalize after node Mamba stream
    after_edge_mamba: true  # Normalize after edge Mamba stream
    after_gnn: true  # Normalize after GNN processing
    before_decoder: true  # Normalize before final decoder projection

data:
  dataset: tuh_eeg
  data_dir: data_ext4/tusz/edf
  cache_dir: cache/tusz
  split_policy: official_tusz
  sampling_rate: 256
  n_channels: 19
  window_size: 60
  stride: 10
  use_balanced_sampling: false  # MUST be false for BGB_LIMIT_FILES to work!
  num_workers: 0
  pin_memory: false
  persistent_workers: false
  prefetch_factor: 2
  validation_split: 0.2

preprocessing:
  montage: "10-20"
  bandpass: [0.5, 120.0]
  notch_freq: 60
  normalize: true
  use_mne: true

training:
  epochs: 1  # Just 1 epoch for smoke
  batch_size: 8  # Restored to baseline after memory fixes
  learning_rate: 5.0e-5  # Reduced for stability with norms
  weight_decay: 0.05
  optimizer: adamw
  gradient_clip: 0.5
  mixed_precision: false  # Disabled for smoke test stability

  # Focal loss for imbalanced data
  loss: focal
  focal_alpha: 0.5
  focal_gamma: 2.0

  scheduler:
    type: cosine
    warmup_ratio: 0.1

  early_stopping:
    patience: 5
    metric: sensitivity_at_10fa

postprocessing:
  hysteresis:
    tau_on: 0.86
    tau_off: 0.78
  morphology:
    opening_kernel: 11
    closing_kernel: 31
  duration:
    min_duration_s: 3.0
    max_duration_s: 600.0
  events:
    tau_merge: 2.0
    confidence_method: mean

evaluation:
  metrics: [taes, sensitivity, specificity, auroc]
  fa_rates: [10, 5, 2.5, 1]
  save_predictions: false
  save_plots: false

logging:
  log_every_n_steps: 10
  log_gradients: false
  log_weights: false